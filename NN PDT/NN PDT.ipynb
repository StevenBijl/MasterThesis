{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d5462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import struct\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3513790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "[32 33 34 35]\n",
      "[38 39]\n"
     ]
    }
   ],
   "source": [
    "### Usable Files\n",
    "\n",
    "# Path File where the Mixed&Sliced signals are stored\n",
    "direction = pathlib.Path(\"Location where data is stored\")\n",
    "\n",
    "file_list = list(direction.iterdir())\n",
    "\n",
    "file_num = len(file_list)\n",
    "\n",
    "\n",
    "# Diving # of test files\n",
    "num_test_files = 2\n",
    "\n",
    "# Locate 80% for training\n",
    "eighty = round(0.8*file_num)\n",
    "\n",
    "# Located 80% - #Test files for validation\n",
    "twenty = file_num-eighty - num_test_files\n",
    "\n",
    "# Listing the files for each category\n",
    "list_of_file_ids_train = np.arange(eighty, dtype=int)\n",
    "\n",
    "list_of_file_ids_val = np.arange(eighty,eighty+twenty-num_test_files, dtype=int)\n",
    "\n",
    "list_of_file_ids_test =np.arange(file_num-num_test_files,file_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f435cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Functions to process the data\n",
    "\n",
    "        ### Unnormalization of each signal individually\n",
    "def Unnormalized(batch_signals):\n",
    "        \n",
    "        return batch_signals\n",
    "        \n",
    "        ### Normalization of each signal individually\n",
    "def Normalized(batch_signals):\n",
    "\n",
    "        for i in range(len(batch_signals)):\n",
    "            batch_signals[i] = batch_signals[i]/np.max(batch_signals[i])\n",
    "            \n",
    "        return batch_signals\n",
    "            \n",
    "        \n",
    "        ### Normalization of the entire value by one common denominator      \n",
    "def Denominator(batch_signals):  \n",
    "    \n",
    "        denominator = 3953.48\n",
    "        batch_signals = batch_signals/denominator\n",
    "        \n",
    "        return batch_signals\n",
    "\n",
    "\n",
    "##### Class\n",
    "\n",
    "class TrainDataset(tf.data.Dataset):\n",
    "\n",
    "    def _generator(file_id):  \n",
    "#         print(f'Using Train Class')\n",
    "        if(file_id == 0):\n",
    "#             print(\"reshuffling\")\n",
    "            np.random.shuffle(list_of_file_ids_train)             \n",
    "\n",
    "        i_file = list_of_file_ids_train[file_id]\n",
    "\n",
    "#         print(f'file_id: {file_id}, i_file: {i_file}')\n",
    "#         print()\n",
    "        signal_filename = direction/f'{i_file+1}.h5'\n",
    "\n",
    "        \n",
    "         # Load the labels and signals from the files\n",
    "        df = pd.read_hdf(signal_filename,key=None)    \n",
    "        \n",
    "        labels = df[variable]\n",
    "        signals = df[df.columns[10:-2]].values\n",
    "        \n",
    "        \n",
    "        # Determine how many batches can be made from this file\n",
    "        num_batches = len(signals) // batch_size\n",
    "\n",
    "        # Shuffle the signals within the file\n",
    "        signal_indices = np.arange(len(signals))\n",
    "        np.random.shuffle(signal_indices)        \n",
    "        \n",
    "        # Loop through each batch in the file\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get the signals and labels for this batch\n",
    "            batch_signal_indices = signal_indices[batch_idx*batch_size:(batch_idx+1)*batch_size]      \n",
    " \n",
    "            batch_signals = signals[batch_signal_indices]\n",
    "            \n",
    "            batch_signals = Processing[process](batch_signals)\n",
    "                \n",
    "            batch_signals = batch_signals[:,:,np.newaxis] # Can also be done with signals = signals[:,:,np.newaxis]\n",
    "            batch_labels = labels.iloc[batch_signal_indices]\n",
    "\n",
    "            # Yield the signals and labels as a tuple\n",
    "            yield batch_signals, batch_labels.values \n",
    "             \n",
    "    def __new__(cls, file_id):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.dtypes.float64, tf.dtypes.float64),\n",
    "            output_shapes=((batch_size, 1998,1), (batch_size, )),\n",
    "            args=(file_id,)\n",
    "        )\n",
    "\n",
    "class ValDataset(tf.data.Dataset):\n",
    "\n",
    "    def _generator(file_id):  \n",
    "#         print(f'Using Val Class')\n",
    "        i_file = list_of_file_ids_val[file_id]\n",
    "    \n",
    "        signal_filename = direction/f'{i_file+1}.h5'\n",
    "\n",
    "         # Load the labels and signals from the files\n",
    "        df = pd.read_hdf(signal_filename,key=None)    \n",
    "        \n",
    "        labels = df[variable]\n",
    "        signals = df[df.columns[10:-2]].values\n",
    "        \n",
    "        \n",
    "        # Determine how many batches can be made from this file\n",
    "        num_batches = len(signals) // batch_size\n",
    "\n",
    "        # Shuffle the signals within the file\n",
    "        signal_indices = np.arange(len(signals))\n",
    "        np.random.shuffle(signal_indices)        \n",
    "        \n",
    "        # Loop through each batch in the file\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get the signals and labels for this batch\n",
    "            batch_signal_indices = signal_indices[batch_idx*batch_size:(batch_idx+1)*batch_size]      \n",
    " \n",
    "            batch_signals = signals[batch_signal_indices]\n",
    "            \n",
    "            batch_signals = Processing[process](batch_signals)\n",
    "                \n",
    "            batch_signals = batch_signals[:,:,np.newaxis] # Can also be done with signals = signals[:,:,np.newaxis]\n",
    "            batch_labels = labels.iloc[batch_signal_indices]\n",
    "\n",
    "            # Yield the signals and labels as a tuple\n",
    "            yield batch_signals, batch_labels.values \n",
    "             \n",
    "    def __new__(cls, file_id):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.dtypes.float64, tf.dtypes.float64),\n",
    "            output_shapes=((batch_size, 1998,1), (batch_size, )),\n",
    "            args=(file_id,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30da325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, activation='relu', input_shape=(1998, 1)))\n",
    "    model.add(Conv1D(filters=8, kernel_size=5, dilation_rate=2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, dilation_rate=2, activation='relu'))\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, strides=2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4407eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_3872\\964900555.py:75: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_3872\\964900555.py:75: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing options\n",
    "Processing = {\n",
    "    \"Unnormalized\": Unnormalized,\n",
    "    \"Normalized\": Normalized,\n",
    "    \"Denominator\": Denominator\n",
    "}\n",
    "Process = [\"Unnormalized\",\"Normalized\",\"Denominator\"]\n",
    "process = Process[1]\n",
    "# Loss Function\n",
    "\n",
    "loss_function = ['mean_absolute_error','mean_squared_error']\n",
    "lf = 1\n",
    "\n",
    "# Training Variables\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "\n",
    "steps_per_epoch = eighty*5000 // batch_size\n",
    "\n",
    "# Learning Rate\n",
    "initial_lr = 1e-03\n",
    "final_lr = 1e-06\n",
    "\n",
    "# initial_lr = 1e-03\n",
    "# final_lr = 1e-03\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = initial_lr * (final_lr/initial_lr)**(epoch/num_epochs)\n",
    "\n",
    "    print(f'Current Learning rate: {lrate}')\n",
    "    return lrate\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "\n",
    "# Configuring training dataset\n",
    "dataset_train = tf.data.Dataset.range(eighty).interleave(\n",
    "        TrainDataset,\n",
    "        cycle_length=2,\n",
    "        num_parallel_calls=2,\n",
    "        deterministic=True).repeat().prefetch(1)\n",
    "\n",
    "\n",
    "\n",
    "# Configuring training dataset\n",
    "dataset_val = tf.data.Dataset.range(twenty-num_test_files).interleave(\n",
    "        ValDataset,\n",
    "        cycle_length=2,\n",
    "        num_parallel_calls=2,\n",
    "        deterministic=True).prefetch(1)\n",
    "\n",
    "\n",
    "# Callback Functions\n",
    "LRS = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "\n",
    "ES = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True,verbose=1)\n",
    "\n",
    "CSV = tf.keras.callbacks.CSVLogger(\"Location_for_csvlog/Log.csv\",\n",
    "                                separator=\",\", append=True)\n",
    "\n",
    "\n",
    "MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    ")\n",
    "\n",
    "callbacks = [MC,LRS,CSV]\n",
    "\n",
    "\n",
    "\n",
    "# Variable of interest\n",
    "variable = 'PDT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d964d44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 61s 9ms/step - loss: 0.0306 - mean_absolute_error: 0.1250 - mean_squared_error: 0.0306 - val_loss: 0.0431 - val_mean_absolute_error: 0.1778 - val_mean_squared_error: 0.0431\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0136 - mean_absolute_error: 0.0877 - mean_squared_error: 0.0136 - val_loss: 0.0642 - val_mean_absolute_error: 0.2307 - val_mean_squared_error: 0.0642\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0097 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0097 - val_loss: 0.0909 - val_mean_absolute_error: 0.2642 - val_mean_squared_error: 0.0909\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0080 - mean_absolute_error: 0.0691 - mean_squared_error: 0.0080 - val_loss: 0.0727 - val_mean_absolute_error: 0.2346 - val_mean_squared_error: 0.0727\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0070 - mean_absolute_error: 0.0646 - mean_squared_error: 0.0070 - val_loss: 0.0134 - val_mean_absolute_error: 0.0933 - val_mean_squared_error: 0.0134\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0091 - mean_absolute_error: 0.0639 - mean_squared_error: 0.0091 - val_loss: 0.0695 - val_mean_absolute_error: 0.1905 - val_mean_squared_error: 0.0695\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0055 - mean_absolute_error: 0.0566 - mean_squared_error: 0.0055 - val_loss: 0.1325 - val_mean_absolute_error: 0.3262 - val_mean_squared_error: 0.1325\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0049 - mean_absolute_error: 0.0529 - mean_squared_error: 0.0049 - val_loss: 0.0181 - val_mean_absolute_error: 0.1177 - val_mean_squared_error: 0.0181\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0043 - mean_absolute_error: 0.0500 - mean_squared_error: 0.0043 - val_loss: 0.0323 - val_mean_absolute_error: 0.1347 - val_mean_squared_error: 0.0323\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0039 - mean_absolute_error: 0.0481 - mean_squared_error: 0.0039 - val_loss: 0.0186 - val_mean_absolute_error: 0.1067 - val_mean_squared_error: 0.0186\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0037 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0037 - val_loss: 0.0158 - val_mean_absolute_error: 0.1048 - val_mean_squared_error: 0.0158\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0036 - mean_absolute_error: 0.0459 - mean_squared_error: 0.0036 - val_loss: 0.0047 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0047\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0034 - mean_absolute_error: 0.0450 - mean_squared_error: 0.0034 - val_loss: 0.0168 - val_mean_absolute_error: 0.1169 - val_mean_squared_error: 0.0168\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0034 - mean_absolute_error: 0.0444 - mean_squared_error: 0.0034 - val_loss: 0.0255 - val_mean_absolute_error: 0.1375 - val_mean_squared_error: 0.0255\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0033 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0033 - val_loss: 0.0048 - val_mean_absolute_error: 0.0530 - val_mean_squared_error: 0.0048\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0032 - mean_absolute_error: 0.0429 - mean_squared_error: 0.0032 - val_loss: 0.0085 - val_mean_absolute_error: 0.0729 - val_mean_squared_error: 0.0085\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0031 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0031 - val_loss: 0.0066 - val_mean_absolute_error: 0.0619 - val_mean_squared_error: 0.0066\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0031 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0031 - val_loss: 0.0042 - val_mean_absolute_error: 0.0493 - val_mean_squared_error: 0.0042\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_absolute_error: 0.0409 - val_mean_squared_error: 0.0029\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_absolute_error: 0.0415 - val_mean_squared_error: 0.0030\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0030 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0030 - val_loss: 0.0050 - val_mean_absolute_error: 0.0542 - val_mean_squared_error: 0.0050\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 46s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0030 - val_loss: 0.0032 - val_mean_absolute_error: 0.0435 - val_mean_squared_error: 0.0032\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0030 - mean_absolute_error: 0.0413 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_mean_absolute_error: 0.0462 - val_mean_squared_error: 0.0036\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_absolute_error: 0.0410 - val_mean_squared_error: 0.0029\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_absolute_error: 0.0400 - val_mean_squared_error: 0.0027\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_mean_absolute_error: 0.0444 - val_mean_squared_error: 0.0034\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_absolute_error: 0.0398 - val_mean_squared_error: 0.0027\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0407 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0401 - val_mean_squared_error: 0.0028\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_absolute_error: 0.0397 - val_mean_squared_error: 0.0027\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0408 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_absolute_error: 0.0398 - val_mean_squared_error: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/5\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 43s 8ms/step - loss: 0.0555 - mean_absolute_error: 0.1558 - mean_squared_error: 0.0555 - val_loss: 36.0546 - val_mean_absolute_error: 5.9966 - val_mean_squared_error: 36.0546\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0217 - mean_absolute_error: 0.1061 - mean_squared_error: 0.0217 - val_loss: 0.0212 - val_mean_absolute_error: 0.1235 - val_mean_squared_error: 0.0212\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0087 - mean_absolute_error: 0.0715 - mean_squared_error: 0.0087 - val_loss: 0.0208 - val_mean_absolute_error: 0.1157 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.0064 - mean_absolute_error: 0.0615 - mean_squared_error: 0.0064 - val_loss: 0.0065 - val_mean_absolute_error: 0.0650 - val_mean_squared_error: 0.0065\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0050 - mean_absolute_error: 0.0544 - mean_squared_error: 0.0050 - val_loss: 0.0059 - val_mean_absolute_error: 0.0596 - val_mean_squared_error: 0.0059\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.0046 - mean_absolute_error: 0.0509 - mean_squared_error: 0.0046 - val_loss: 0.0191 - val_mean_absolute_error: 0.1087 - val_mean_squared_error: 0.0191\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0042 - mean_absolute_error: 0.0494 - mean_squared_error: 0.0042 - val_loss: 0.0089 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0089\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.0038 - mean_absolute_error: 0.0474 - mean_squared_error: 0.0038 - val_loss: 0.0134 - val_mean_absolute_error: 0.0924 - val_mean_squared_error: 0.0134\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.0037 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0037 - val_loss: 0.0102 - val_mean_absolute_error: 0.0804 - val_mean_squared_error: 0.0102\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0035 - mean_absolute_error: 0.0454 - mean_squared_error: 0.0035 - val_loss: 0.0252 - val_mean_absolute_error: 0.1235 - val_mean_squared_error: 0.0252\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.0034 - mean_absolute_error: 0.0445 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_mean_absolute_error: 0.0481 - val_mean_squared_error: 0.0040\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0033 - mean_absolute_error: 0.0440 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_absolute_error: 0.0443 - val_mean_squared_error: 0.0033\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0032 - mean_absolute_error: 0.0434 - mean_squared_error: 0.0032 - val_loss: 0.0048 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0048\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0032 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0032 - val_loss: 0.0071 - val_mean_absolute_error: 0.0648 - val_mean_squared_error: 0.0071\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0031 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0031 - val_loss: 0.0040 - val_mean_absolute_error: 0.0481 - val_mean_squared_error: 0.0040\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0031 - mean_absolute_error: 0.0425 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_absolute_error: 0.0421 - val_mean_squared_error: 0.0030\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0030 - val_loss: 0.0032 - val_mean_absolute_error: 0.0436 - val_mean_squared_error: 0.0032\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0030 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0030 - val_loss: 0.0051 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0051\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0030 - mean_absolute_error: 0.0420 - mean_squared_error: 0.0030 - val_loss: 0.0051 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0051\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0030 - mean_absolute_error: 0.0417 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_absolute_error: 0.0410 - val_mean_squared_error: 0.0029\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.0030 - mean_absolute_error: 0.0418 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_absolute_error: 0.0413 - val_mean_squared_error: 0.0029\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0416 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_absolute_error: 0.0412 - val_mean_squared_error: 0.0029\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0030 - mean_absolute_error: 0.0417 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_absolute_error: 0.0409 - val_mean_squared_error: 0.0028\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0409 - val_mean_squared_error: 0.0028\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0416 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0409 - val_mean_squared_error: 0.0028\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0407 - val_mean_squared_error: 0.0028\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.0029 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0408 - val_mean_squared_error: 0.0028\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0029 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0408 - val_mean_squared_error: 0.0028\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0408 - val_mean_squared_error: 0.0028\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_absolute_error: 0.0407 - val_mean_squared_error: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/5\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.0221 - mean_absolute_error: 0.1049 - mean_squared_error: 0.0221 - val_loss: 0.4625 - val_mean_absolute_error: 0.6042 - val_mean_squared_error: 0.4625\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0080 - mean_absolute_error: 0.0688 - mean_squared_error: 0.0080 - val_loss: 0.3793 - val_mean_absolute_error: 0.6009 - val_mean_squared_error: 0.3793\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0060 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0060 - val_loss: 0.1427 - val_mean_absolute_error: 0.3018 - val_mean_squared_error: 0.1427\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0051 - mean_absolute_error: 0.0546 - mean_squared_error: 0.0051 - val_loss: 0.0989 - val_mean_absolute_error: 0.2433 - val_mean_squared_error: 0.0989\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0045 - mean_absolute_error: 0.0510 - mean_squared_error: 0.0045 - val_loss: 0.0102 - val_mean_absolute_error: 0.0798 - val_mean_squared_error: 0.0102\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.0041 - mean_absolute_error: 0.0489 - mean_squared_error: 0.0041 - val_loss: 0.0037 - val_mean_absolute_error: 0.0468 - val_mean_squared_error: 0.0037\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0038 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0038 - val_loss: 0.0307 - val_mean_absolute_error: 0.1566 - val_mean_squared_error: 0.0307\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.0037 - mean_absolute_error: 0.0459 - mean_squared_error: 0.0037 - val_loss: 0.0225 - val_mean_absolute_error: 0.1230 - val_mean_squared_error: 0.0225\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 46s 9ms/step - loss: 0.0034 - mean_absolute_error: 0.0446 - mean_squared_error: 0.0034 - val_loss: 0.0068 - val_mean_absolute_error: 0.0631 - val_mean_squared_error: 0.0068\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0034 - mean_absolute_error: 0.0442 - mean_squared_error: 0.0034 - val_loss: 0.0050 - val_mean_absolute_error: 0.0555 - val_mean_squared_error: 0.0050\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0032 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0032 - val_loss: 0.0051 - val_mean_absolute_error: 0.0562 - val_mean_squared_error: 0.0051\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0031 - mean_absolute_error: 0.0428 - mean_squared_error: 0.0031 - val_loss: 0.0055 - val_mean_absolute_error: 0.0564 - val_mean_squared_error: 0.0055\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0031 - mean_absolute_error: 0.0422 - mean_squared_error: 0.0031 - val_loss: 0.0044 - val_mean_absolute_error: 0.0507 - val_mean_squared_error: 0.0044\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0030 - mean_absolute_error: 0.0418 - mean_squared_error: 0.0030 - val_loss: 0.0037 - val_mean_absolute_error: 0.0485 - val_mean_squared_error: 0.0037\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0029 - val_loss: 0.0037 - val_mean_absolute_error: 0.0462 - val_mean_squared_error: 0.0037\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0412 - mean_squared_error: 0.0029 - val_loss: 0.0051 - val_mean_absolute_error: 0.0572 - val_mean_squared_error: 0.0051\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_absolute_error: 0.0420 - val_mean_squared_error: 0.0029\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0029 - val_loss: 0.0032 - val_mean_absolute_error: 0.0439 - val_mean_squared_error: 0.0032\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0028 - mean_absolute_error: 0.0405 - mean_squared_error: 0.0028 - val_loss: 0.0040 - val_mean_absolute_error: 0.0476 - val_mean_squared_error: 0.0040\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0028 - val_loss: 0.0030 - val_mean_absolute_error: 0.0424 - val_mean_squared_error: 0.0030\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0028 - mean_absolute_error: 0.0405 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0399 - val_mean_squared_error: 0.0027\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_absolute_error: 0.0408 - val_mean_squared_error: 0.0028\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0027 - mean_absolute_error: 0.0401 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_absolute_error: 0.0417 - val_mean_squared_error: 0.0029\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0402 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_absolute_error: 0.0391 - val_mean_squared_error: 0.0026\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.0027 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_absolute_error: 0.0398 - val_mean_squared_error: 0.0027\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0028 - mean_absolute_error: 0.0401 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_absolute_error: 0.0392 - val_mean_squared_error: 0.0026\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0027 - mean_absolute_error: 0.0401 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_absolute_error: 0.0391 - val_mean_squared_error: 0.0026\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0027 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_absolute_error: 0.0397 - val_mean_squared_error: 0.0027\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0027 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_absolute_error: 0.0391 - val_mean_squared_error: 0.0026\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0027 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_absolute_error: 0.0391 - val_mean_squared_error: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/5\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 40s 7ms/step - loss: 0.0454 - mean_absolute_error: 0.1354 - mean_squared_error: 0.0454 - val_loss: 0.8579 - val_mean_absolute_error: 0.9177 - val_mean_squared_error: 0.8579\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0198 - mean_absolute_error: 0.1064 - mean_squared_error: 0.0198 - val_loss: 5.6926 - val_mean_absolute_error: 2.3716 - val_mean_squared_error: 5.6926\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0159 - mean_absolute_error: 0.0929 - mean_squared_error: 0.0159 - val_loss: 0.2252 - val_mean_absolute_error: 0.4517 - val_mean_squared_error: 0.2252\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0094 - mean_absolute_error: 0.0744 - mean_squared_error: 0.0094 - val_loss: 0.1298 - val_mean_absolute_error: 0.2988 - val_mean_squared_error: 0.1298\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0089 - mean_absolute_error: 0.0704 - mean_squared_error: 0.0089 - val_loss: 9.4655 - val_mean_absolute_error: 3.0693 - val_mean_squared_error: 9.4655\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0073 - mean_absolute_error: 0.0646 - mean_squared_error: 0.0073 - val_loss: 0.0078 - val_mean_absolute_error: 0.0706 - val_mean_squared_error: 0.0078\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0067 - mean_absolute_error: 0.0620 - mean_squared_error: 0.0067 - val_loss: 1.0588 - val_mean_absolute_error: 1.0162 - val_mean_squared_error: 1.0588\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0064 - mean_absolute_error: 0.0601 - mean_squared_error: 0.0064 - val_loss: 0.6938 - val_mean_absolute_error: 0.8167 - val_mean_squared_error: 0.6938\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0060 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0060 - val_loss: 1.1106 - val_mean_absolute_error: 1.0385 - val_mean_squared_error: 1.1106\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0058 - mean_absolute_error: 0.0567 - mean_squared_error: 0.0058 - val_loss: 0.0445 - val_mean_absolute_error: 0.1737 - val_mean_squared_error: 0.0445\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0055 - mean_absolute_error: 0.0553 - mean_squared_error: 0.0055 - val_loss: 0.8098 - val_mean_absolute_error: 0.8860 - val_mean_squared_error: 0.8098\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0054 - mean_absolute_error: 0.0543 - mean_squared_error: 0.0054 - val_loss: 0.0145 - val_mean_absolute_error: 0.0899 - val_mean_squared_error: 0.0145\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0052 - mean_absolute_error: 0.0535 - mean_squared_error: 0.0052 - val_loss: 0.0074 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0074\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0051 - mean_absolute_error: 0.0530 - mean_squared_error: 0.0051 - val_loss: 0.0504 - val_mean_absolute_error: 0.1780 - val_mean_squared_error: 0.0504\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0050 - mean_absolute_error: 0.0524 - mean_squared_error: 0.0050 - val_loss: 0.0381 - val_mean_absolute_error: 0.1646 - val_mean_squared_error: 0.0381\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0049 - mean_absolute_error: 0.0520 - mean_squared_error: 0.0049 - val_loss: 0.0247 - val_mean_absolute_error: 0.1285 - val_mean_squared_error: 0.0247\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0048 - mean_absolute_error: 0.0513 - mean_squared_error: 0.0048 - val_loss: 0.0144 - val_mean_absolute_error: 0.0888 - val_mean_squared_error: 0.0144\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0048 - mean_absolute_error: 0.0514 - mean_squared_error: 0.0048 - val_loss: 0.0269 - val_mean_absolute_error: 0.1341 - val_mean_squared_error: 0.0269\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0048 - mean_absolute_error: 0.0510 - mean_squared_error: 0.0048 - val_loss: 0.0489 - val_mean_absolute_error: 0.1900 - val_mean_squared_error: 0.0489\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0047 - mean_absolute_error: 0.0509 - mean_squared_error: 0.0047 - val_loss: 0.0112 - val_mean_absolute_error: 0.0810 - val_mean_squared_error: 0.0112\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0047 - mean_absolute_error: 0.0508 - mean_squared_error: 0.0047 - val_loss: 0.0084 - val_mean_absolute_error: 0.0697 - val_mean_squared_error: 0.0084\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0047 - mean_absolute_error: 0.0506 - mean_squared_error: 0.0047 - val_loss: 0.0090 - val_mean_absolute_error: 0.0688 - val_mean_squared_error: 0.0090\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0047 - mean_absolute_error: 0.0506 - mean_squared_error: 0.0047 - val_loss: 0.0070 - val_mean_absolute_error: 0.0628 - val_mean_squared_error: 0.0070\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0047 - mean_absolute_error: 0.0505 - mean_squared_error: 0.0047 - val_loss: 0.0066 - val_mean_absolute_error: 0.0588 - val_mean_squared_error: 0.0066\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0046 - mean_absolute_error: 0.0504 - mean_squared_error: 0.0046 - val_loss: 0.0057 - val_mean_absolute_error: 0.0548 - val_mean_squared_error: 0.0057\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0046 - mean_absolute_error: 0.0504 - mean_squared_error: 0.0046 - val_loss: 0.0047 - val_mean_absolute_error: 0.0513 - val_mean_squared_error: 0.0047\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0046 - mean_absolute_error: 0.0502 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_absolute_error: 0.0487 - val_mean_squared_error: 0.0043\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0046 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0046 - val_loss: 0.0043 - val_mean_absolute_error: 0.0488 - val_mean_squared_error: 0.0043\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0046 - mean_absolute_error: 0.0501 - mean_squared_error: 0.0046 - val_loss: 0.0058 - val_mean_absolute_error: 0.0569 - val_mean_squared_error: 0.0058\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0046 - mean_absolute_error: 0.0504 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_absolute_error: 0.0496 - val_mean_squared_error: 0.0044\n",
      "Run 5/5\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 42s 7ms/step - loss: 0.0293 - mean_absolute_error: 0.1167 - mean_squared_error: 0.0293 - val_loss: 0.4797 - val_mean_absolute_error: 0.6802 - val_mean_squared_error: 0.4797\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0787 - mean_squared_error: 0.0108 - val_loss: 0.0089 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0089\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0065 - mean_absolute_error: 0.0622 - mean_squared_error: 0.0065 - val_loss: 0.0242 - val_mean_absolute_error: 0.1226 - val_mean_squared_error: 0.0242\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0051 - mean_absolute_error: 0.0556 - mean_squared_error: 0.0051 - val_loss: 0.0822 - val_mean_absolute_error: 0.2309 - val_mean_squared_error: 0.0822\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0082 - mean_absolute_error: 0.0543 - mean_squared_error: 0.0082 - val_loss: 0.0061 - val_mean_absolute_error: 0.0618 - val_mean_squared_error: 0.0061\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0044 - mean_absolute_error: 0.0514 - mean_squared_error: 0.0044 - val_loss: 0.0508 - val_mean_absolute_error: 0.1882 - val_mean_squared_error: 0.0508\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0037 - mean_absolute_error: 0.0466 - mean_squared_error: 0.0037 - val_loss: 0.0985 - val_mean_absolute_error: 0.2287 - val_mean_squared_error: 0.0985\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0043 - mean_absolute_error: 0.0488 - mean_squared_error: 0.0043 - val_loss: 0.0097 - val_mean_absolute_error: 0.0799 - val_mean_squared_error: 0.0097\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0035 - mean_absolute_error: 0.0458 - mean_squared_error: 0.0035 - val_loss: 0.0229 - val_mean_absolute_error: 0.1211 - val_mean_squared_error: 0.0229\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 34s 7ms/step - loss: 0.0033 - mean_absolute_error: 0.0445 - mean_squared_error: 0.0033 - val_loss: 0.0512 - val_mean_absolute_error: 0.1591 - val_mean_squared_error: 0.0512\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0033 - mean_absolute_error: 0.0440 - mean_squared_error: 0.0033 - val_loss: 0.0146 - val_mean_absolute_error: 0.0979 - val_mean_squared_error: 0.0146\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 0.0032 - mean_absolute_error: 0.0433 - mean_squared_error: 0.0032 - val_loss: 0.0111 - val_mean_absolute_error: 0.0813 - val_mean_squared_error: 0.0111\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0031 - mean_absolute_error: 0.0426 - mean_squared_error: 0.0031 - val_loss: 0.0042 - val_mean_absolute_error: 0.0499 - val_mean_squared_error: 0.0042\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0030 - mean_absolute_error: 0.0424 - mean_squared_error: 0.0030 - val_loss: 0.0174 - val_mean_absolute_error: 0.1007 - val_mean_squared_error: 0.0174\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0030 - mean_absolute_error: 0.0420 - mean_squared_error: 0.0030 - val_loss: 0.0070 - val_mean_absolute_error: 0.0647 - val_mean_squared_error: 0.0070\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0418 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_mean_absolute_error: 0.0468 - val_mean_squared_error: 0.0036\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 0.0029 - mean_absolute_error: 0.0416 - mean_squared_error: 0.0029 - val_loss: 0.0046 - val_mean_absolute_error: 0.0517 - val_mean_squared_error: 0.0046\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0029 - mean_absolute_error: 0.0413 - mean_squared_error: 0.0029 - val_loss: 0.0032 - val_mean_absolute_error: 0.0437 - val_mean_squared_error: 0.0032\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0029 - mean_absolute_error: 0.0412 - mean_squared_error: 0.0029 - val_loss: 0.0033 - val_mean_absolute_error: 0.0441 - val_mean_squared_error: 0.0033\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - mean_squared_error: 0.0029 - val_loss: 0.0041 - val_mean_absolute_error: 0.0492 - val_mean_squared_error: 0.0041\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_absolute_error: 0.0401 - val_mean_squared_error: 0.0027\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 42s 8ms/step - loss: 0.0028 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0028 - val_loss: 0.0029 - val_mean_absolute_error: 0.0413 - val_mean_squared_error: 0.0029\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0028 - val_loss: 0.0032 - val_mean_absolute_error: 0.0432 - val_mean_squared_error: 0.0032\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 43s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0407 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_absolute_error: 0.0404 - val_mean_squared_error: 0.0028\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0407 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_absolute_error: 0.0408 - val_mean_squared_error: 0.0028\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0408 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0403 - val_mean_squared_error: 0.0027\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0028 - mean_absolute_error: 0.0407 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0399 - val_mean_squared_error: 0.0027\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0408 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0399 - val_mean_squared_error: 0.0027\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0028 - mean_absolute_error: 0.0408 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0400 - val_mean_squared_error: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0028 - mean_absolute_error: 0.0407 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_absolute_error: 0.0399 - val_mean_squared_error: 0.0027\n"
     ]
    }
   ],
   "source": [
    "num_runs = 5  # Number of times to run the model\n",
    "\n",
    "# The following method ensures that the initialization starts random for each training\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}/{num_runs}\")\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "    \n",
    "    MC_path = f\"Location_for_model_checkpoint/model_checkpoint_{run + 1}.h5\"\n",
    "    MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    "    )\n",
    "\n",
    "    callbacks = [MC,LRS,CSV]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(x=dataset_train, validation_data = dataset_val, steps_per_epoch=steps_per_epoch, epochs=num_epochs,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
