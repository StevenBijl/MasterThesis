{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a563ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import struct\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699ed76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import struct\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3954059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "[32 33 34 35]\n",
      "[38 39]\n"
     ]
    }
   ],
   "source": [
    "### Usable Files\n",
    "\n",
    "direction = pathlib.Path(\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Data/Detector97/Filtered/Processed/\")\n",
    "\n",
    "# direction = pathlib.Path(\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Data/Detector97/Unfiltered/Processed/\")\n",
    "\n",
    "file_list = list(direction.iterdir())\n",
    "\n",
    "file_num = len(file_list)\n",
    "\n",
    "step = 0.8\n",
    "\n",
    "num_test_files = 2\n",
    "eighty = round(step*file_num)\n",
    "twenty = file_num-eighty - num_test_files\n",
    "\n",
    "list_of_file_ids_train = np.arange(eighty, dtype=int)\n",
    "print(list_of_file_ids_train)\n",
    "list_of_file_ids_val = np.arange(eighty,eighty+twenty-num_test_files, dtype=int)\n",
    "print(list_of_file_ids_val)\n",
    "list_of_file_ids_test =np.arange(file_num-num_test_files,file_num)\n",
    "print(list_of_file_ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13410ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions to process the data\n",
    "\n",
    "        ### Unnormalization of each signal individually\n",
    "def Unnormalized(batch_signals):\n",
    "        \n",
    "        return batch_signals\n",
    "        \n",
    "        ### Normalization of each signal individually\n",
    "def Normalized(batch_signals):\n",
    "\n",
    "        for i in range(len(batch_signals)):\n",
    "            batch_signals[i] = batch_signals[i]/np.max(batch_signals[i])\n",
    "            \n",
    "        return batch_signals\n",
    "            \n",
    "        \n",
    "        ### Normalization of the entire value by one common denominator      \n",
    "def Denominator(batch_signals):  \n",
    "    \n",
    "        denominator = 3953.48\n",
    "        batch_signals = batch_signals/denominator\n",
    "        \n",
    "        return batch_signals\n",
    "\n",
    "\n",
    "##### Class\n",
    "\n",
    "class TrainDataset(tf.data.Dataset):\n",
    "\n",
    "    def _generator(file_id):  \n",
    "#         print(f'Using Train Class')\n",
    "        if(file_id == 0):\n",
    "#             print(\"reshuffling\")\n",
    "            np.random.shuffle(list_of_file_ids_train)             \n",
    "\n",
    "        i_file = list_of_file_ids_train[file_id]\n",
    "\n",
    "#         print(f'file_id: {file_id}, i_file: {i_file}')\n",
    "#         print()\n",
    "        signal_filename = direction/f'{i_file+1}.h5'\n",
    "\n",
    "        \n",
    "         # Load the labels and signals from the files\n",
    "        df = pd.read_hdf(signal_filename,key=None)  \n",
    "\n",
    "        mask = (df['A'] == mass) & (df['Z'] == energy)\n",
    "        df_new = df[~mask]       \n",
    "\n",
    "        \n",
    "        labels1 = df_new.iloc[:,9].values\n",
    "        labels2 = df_new['ToF'].values\n",
    "        labels = labels1+labels2\n",
    "        \n",
    "        signals = df_new[df_new.columns[10:-2]].values\n",
    "        \n",
    "        \n",
    "        # Determine how many batches can be made from this file\n",
    "        num_batches = len(signals) // batch_size\n",
    "\n",
    "        # Shuffle the signals within the file\n",
    "        signal_indices = np.arange(len(signals))\n",
    "        np.random.shuffle(signal_indices)        \n",
    "        \n",
    "        # Loop through each batch in the file\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get the signals and labels for this batch\n",
    "            batch_signal_indices = signal_indices[batch_idx*batch_size:(batch_idx+1)*batch_size]      \n",
    " \n",
    "            batch_signals = signals[batch_signal_indices]\n",
    "            \n",
    "            batch_signals = Processing[process](batch_signals)\n",
    "                \n",
    "            batch_signals = batch_signals[:,:,np.newaxis] # Can also be done with signals = signals[:,:,np.newaxis]\n",
    "            batch_labels = labels[batch_signal_indices]\n",
    "\n",
    "            # Yield the signals and labels as a tuple\n",
    "            yield batch_signals, batch_labels \n",
    "             \n",
    "    def __new__(cls, file_id):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.dtypes.float64, tf.dtypes.float64),\n",
    "            output_shapes=((batch_size, 1998,1), (batch_size, )),\n",
    "            args=(file_id,)\n",
    "        )\n",
    "    \n",
    "class ValDataset(tf.data.Dataset):\n",
    "\n",
    "    def _generator(file_id):  \n",
    "#         print(f'Using Val Class')\n",
    "        i_file = list_of_file_ids_val[file_id]\n",
    "    \n",
    "        signal_filename = direction/f'{i_file+1}.h5'\n",
    "\n",
    "         # Load the labels and signals from the files\n",
    "        df = pd.read_hdf(signal_filename,key=None)  \n",
    "\n",
    "        mask = (df['A'] == mass) & (df['Z'] == energy)\n",
    "        df_new = df[~mask]       \n",
    "\n",
    "        \n",
    "        labels1 = df_new.iloc[:,9].values\n",
    "        labels2 = df_new['ToF'].values\n",
    "        labels = labels1+labels2\n",
    "        \n",
    "        signals = df_new[df_new.columns[10:-2]].values\n",
    "        \n",
    "        \n",
    "        # Determine how many batches can be made from this file\n",
    "        num_batches = len(signals) // batch_size\n",
    "\n",
    "        # Shuffle the signals within the file\n",
    "        signal_indices = np.arange(len(signals))\n",
    "        np.random.shuffle(signal_indices)        \n",
    "        \n",
    "        # Loop through each batch in the file\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get the signals and labels for this batch\n",
    "            batch_signal_indices = signal_indices[batch_idx*batch_size:(batch_idx+1)*batch_size]      \n",
    " \n",
    "            batch_signals = signals[batch_signal_indices]\n",
    "            \n",
    "            batch_signals = Processing[process](batch_signals)\n",
    "                \n",
    "            batch_signals = batch_signals[:,:,np.newaxis] # Can also be done with signals = signals[:,:,np.newaxis]\n",
    "            batch_labels = labels[batch_signal_indices]\n",
    "\n",
    "            # Yield the signals and labels as a tuple\n",
    "            yield batch_signals, batch_labels\n",
    "             \n",
    "    def __new__(cls, file_id):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            output_types=(tf.dtypes.float64, tf.dtypes.float64),\n",
    "            output_shapes=((batch_size, 1998,1), (batch_size, )),\n",
    "            args=(file_id,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41693a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=5, activation='relu', input_shape=(1998, 1)))\n",
    "    model.add(Conv1D(filters=8, kernel_size=5, dilation_rate=2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, dilation_rate=2, activation='relu'))\n",
    "    model.add(Conv1D(filters=4, kernel_size=5, strides=2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d27112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_5800\\243264754.py:80: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_5800\\243264754.py:80: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing options\n",
    "Processing = {\n",
    "    \"Unnormalized\": Unnormalized,\n",
    "    \"Normalized\": Normalized,\n",
    "    \"Denominator\": Denominator\n",
    "}\n",
    "Process = [\"Unnormalized\",\"Normalized\",\"Denominator\"]\n",
    "process = Process[2]\n",
    "# Loss Function\n",
    "\n",
    "loss_function = ['mean_absolute_error','mean_squared_error']\n",
    "lf = 1\n",
    "\n",
    "# Training Variables\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "\n",
    "steps_per_epoch = eighty*5000 // batch_size\n",
    "\n",
    "# Learning Rate\n",
    "initial_lr = 1e-03\n",
    "final_lr = 1e-06\n",
    "\n",
    "# initial_lr = 1e-03\n",
    "# final_lr = 1e-03\n",
    "\n",
    "def step_decay(epoch):\n",
    "    lrate = initial_lr * (final_lr/initial_lr)**(epoch/num_epochs)\n",
    "\n",
    "    print(f'Current Learning rate: {lrate}')\n",
    "    return lrate\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "\n",
    "# Configuring training dataset\n",
    "dataset_train = tf.data.Dataset.range(eighty).interleave(\n",
    "        TrainDataset,\n",
    "        cycle_length=2,\n",
    "        num_parallel_calls=2,\n",
    "        deterministic=True).repeat().prefetch(1)\n",
    "\n",
    "\n",
    "\n",
    "# Configuring training dataset\n",
    "dataset_val = tf.data.Dataset.range(twenty-num_test_files).interleave(\n",
    "        ValDataset,\n",
    "        cycle_length=2,\n",
    "        num_parallel_calls=2,\n",
    "        deterministic=True).prefetch(1)\n",
    "\n",
    "\n",
    "# Callback Functions\n",
    "LRS = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "\n",
    "ES = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True,verbose=1)\n",
    "\n",
    "CSV = tf.keras.callbacks.CSVLogger(\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Data/Log.csv\",\n",
    "                                separator=\",\", append=True)\n",
    "\n",
    "MC_path = f\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Trainings/model_checkpoint.h5\"\n",
    "MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    ")\n",
    "\n",
    "callbacks = [MC,LRS,CSV]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac9a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 104. 105. 110. 127. 130. 133. 135. 136. 140. 143. 149.  80.  85.\n",
      "  90.  91.  95.  97.]\n",
      "[80.0, 85.0, 90.0, 91.0, 95.0, 97.0, 100.0, 104.0, 105.0, 110.0, 127.0, 130.0, 133.0, 135.0, 136.0, 140.0, 143.0, 149.0]\n",
      "\n",
      "80.0 94.0\n",
      "\n",
      "85.0 49.0\n",
      "85.0 58.0\n",
      "85.0 66.0\n",
      "85.0 75.0\n",
      "85.0 83.0\n",
      "85.0 92.0\n",
      "85.0 100.0\n",
      "\n",
      "90.0 52.0\n",
      "90.0 61.0\n",
      "90.0 70.0\n",
      "90.0 79.0\n",
      "90.0 88.0\n",
      "90.0 97.0\n",
      "90.0 106.0\n",
      "\n",
      "91.0 20.0\n",
      "91.0 26.0\n",
      "91.0 33.0\n",
      "91.0 40.0\n",
      "91.0 47.0\n",
      "91.0 54.0\n",
      "\n",
      "95.0 55.0\n",
      "95.0 65.0\n",
      "95.0 74.0\n",
      "95.0 84.0\n",
      "95.0 93.0\n",
      "95.0 103.0\n",
      "\n",
      "97.0 27.0\n",
      "97.0 34.0\n",
      "97.0 41.0\n",
      "97.0 48.0\n",
      "97.0 55.0\n",
      "\n",
      "100.0 34.0\n",
      "100.0 41.0\n",
      "100.0 48.0\n",
      "100.0 58.0\n",
      "100.0 68.0\n",
      "100.0 78.0\n",
      "100.0 88.0\n",
      "100.0 98.0\n",
      "100.0 108.0\n",
      "\n",
      "104.0 22.0\n",
      "104.0 30.0\n",
      "104.0 38.0\n",
      "104.0 46.0\n",
      "104.0 54.0\n",
      "104.0 62.0\n",
      "\n",
      "105.0 61.0\n",
      "105.0 72.0\n",
      "105.0 82.0\n",
      "105.0 93.0\n",
      "105.0 103.0\n",
      "\n",
      "110.0 47.0\n",
      "110.0 63.0\n",
      "110.0 64.0\n",
      "110.0 75.0\n",
      "110.0 86.0\n",
      "110.0 97.0\n",
      "\n",
      "127.0 52.0\n",
      "127.0 61.0\n",
      "\n",
      "130.0 28.0\n",
      "130.0 38.0\n",
      "130.0 48.0\n",
      "130.0 58.0\n",
      "130.0 68.0\n",
      "130.0 76.0\n",
      "130.0 78.0\n",
      "130.0 89.0\n",
      "\n",
      "133.0 55.0\n",
      "133.0 65.0\n",
      "\n",
      "135.0 79.0\n",
      "\n",
      "136.0 38.0\n",
      "136.0 48.0\n",
      "136.0 58.0\n",
      "136.0 68.0\n",
      "136.0 78.0\n",
      "\n",
      "140.0 48.0\n",
      "140.0 58.0\n",
      "140.0 68.0\n",
      "\n",
      "143.0 31.0\n",
      "143.0 42.0\n",
      "143.0 53.0\n",
      "143.0 64.0\n",
      "\n",
      "149.0 42.0\n",
      "149.0 53.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(file_list[0], key=None)\n",
    "\n",
    "unique_mass = df['A'].unique()\n",
    "# Assuming you have already loaded the DataFrame 'df'\n",
    "\n",
    "# Step 1: Group by 'A' (mass) and 'Z' (energy) and count the occurrences\n",
    "grouped = df.groupby(['A', 'Z']).size().reset_index(name='count')\n",
    "\n",
    "mass_subgroups = grouped.groupby('A')\n",
    "\n",
    "count = mass_subgroups.count\n",
    "\n",
    "print(unique_mass)\n",
    "\n",
    "# subgroup = mass_subgroups.get_group(85)\n",
    "# for i in range(len(subgroup)):\n",
    "#     print(subgroup.iloc[i][0])\n",
    "#     print(subgroup.iloc[i][1])\n",
    "#     mask = (df['A'] == subgroup.iloc[i][0]) & (df['Z'] == subgroup.iloc[i][1])\n",
    "#     df_new = df[~mask]\n",
    "#     print(len(df[mask]))\n",
    "\n",
    "#     print(len(df_new))\n",
    "mass_list = sorted(unique_mass)\n",
    "print(mass_list)\n",
    "for Mass in mass_list:\n",
    "    \n",
    "    subgroup = mass_subgroups.get_group(Mass)\n",
    "    print()\n",
    "    for i in range(len(subgroup)):\n",
    "        mass = subgroup.iloc[i][0]\n",
    "        energy = subgroup.iloc[i][1]\n",
    "\n",
    "        print(mass,energy)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b7c3742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 88.0\n",
      "Run 1/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 99s 14ms/step - loss: 1298.8530 - mean_absolute_error: 4.0536 - mean_squared_error: 1298.8530 - val_loss: 0.1926 - val_mean_absolute_error: 0.2879 - val_mean_squared_error: 0.1926\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.3634 - mean_absolute_error: 0.4726 - mean_squared_error: 0.3634 - val_loss: 2.7382 - val_mean_absolute_error: 1.6483 - val_mean_squared_error: 2.7382\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.2739 - mean_absolute_error: 0.4171 - mean_squared_error: 0.2739 - val_loss: 0.5208 - val_mean_absolute_error: 0.7100 - val_mean_squared_error: 0.5208\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.1409 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1409 - val_loss: 0.0664 - val_mean_absolute_error: 0.2321 - val_mean_squared_error: 0.0664\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.1044 - mean_absolute_error: 0.2564 - mean_squared_error: 0.1044 - val_loss: 0.0135 - val_mean_absolute_error: 0.0868 - val_mean_squared_error: 0.0135\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0737 - mean_absolute_error: 0.2086 - mean_squared_error: 0.0737 - val_loss: 2.1379 - val_mean_absolute_error: 1.4580 - val_mean_squared_error: 2.1379\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0469 - mean_absolute_error: 0.1690 - mean_squared_error: 0.0469 - val_loss: 2.1019 - val_mean_absolute_error: 1.4455 - val_mean_squared_error: 2.1019\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0411 - mean_absolute_error: 0.1584 - mean_squared_error: 0.0411 - val_loss: 1.6992 - val_mean_absolute_error: 1.2989 - val_mean_squared_error: 1.6992\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0364 - mean_absolute_error: 0.1507 - mean_squared_error: 0.0364 - val_loss: 0.7879 - val_mean_absolute_error: 0.8809 - val_mean_squared_error: 0.7879\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 57s 11ms/step - loss: 0.0295 - mean_absolute_error: 0.1345 - mean_squared_error: 0.0295 - val_loss: 2.1895 - val_mean_absolute_error: 1.4757 - val_mean_squared_error: 2.1895\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0243 - mean_absolute_error: 0.1202 - mean_squared_error: 0.0243 - val_loss: 0.1140 - val_mean_absolute_error: 0.3206 - val_mean_squared_error: 0.1140\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0212 - mean_absolute_error: 0.1126 - mean_squared_error: 0.0212 - val_loss: 0.0213 - val_mean_absolute_error: 0.1157 - val_mean_squared_error: 0.0213\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0203 - mean_absolute_error: 0.1093 - mean_squared_error: 0.0203 - val_loss: 0.0280 - val_mean_absolute_error: 0.1406 - val_mean_squared_error: 0.0280\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0182 - mean_absolute_error: 0.1039 - mean_squared_error: 0.0182 - val_loss: 0.1450 - val_mean_absolute_error: 0.3671 - val_mean_squared_error: 0.1450\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0175 - mean_absolute_error: 0.1011 - mean_squared_error: 0.0175 - val_loss: 0.0145 - val_mean_absolute_error: 0.0925 - val_mean_squared_error: 0.0145\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0162 - mean_absolute_error: 0.0968 - mean_squared_error: 0.0162 - val_loss: 0.3065 - val_mean_absolute_error: 0.5434 - val_mean_squared_error: 0.3065\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0150 - mean_absolute_error: 0.0925 - mean_squared_error: 0.0150 - val_loss: 0.0266 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0266\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0139 - mean_absolute_error: 0.0888 - mean_squared_error: 0.0139 - val_loss: 0.0912 - val_mean_absolute_error: 0.2851 - val_mean_squared_error: 0.0912\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0136 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0136 - val_loss: 0.0115 - val_mean_absolute_error: 0.0794 - val_mean_squared_error: 0.0115\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0128 - mean_absolute_error: 0.0852 - mean_squared_error: 0.0128 - val_loss: 0.0172 - val_mean_absolute_error: 0.1031 - val_mean_squared_error: 0.0172\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0127 - mean_absolute_error: 0.0838 - mean_squared_error: 0.0127 - val_loss: 0.0607 - val_mean_absolute_error: 0.2263 - val_mean_squared_error: 0.0607\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0125 - mean_absolute_error: 0.0834 - mean_squared_error: 0.0125 - val_loss: 0.0164 - val_mean_absolute_error: 0.0990 - val_mean_squared_error: 0.0164\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0123 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0123 - val_loss: 0.0180 - val_mean_absolute_error: 0.1046 - val_mean_squared_error: 0.0180\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 57s 11ms/step - loss: 0.0120 - mean_absolute_error: 0.0818 - mean_squared_error: 0.0120 - val_loss: 0.0124 - val_mean_absolute_error: 0.0834 - val_mean_squared_error: 0.0124\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0120 - mean_absolute_error: 0.0813 - mean_squared_error: 0.0120 - val_loss: 0.0216 - val_mean_absolute_error: 0.1179 - val_mean_squared_error: 0.0216\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0117 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0117 - val_loss: 0.0164 - val_mean_absolute_error: 0.0981 - val_mean_squared_error: 0.0164\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0119 - mean_absolute_error: 0.0805 - mean_squared_error: 0.0119 - val_loss: 0.0203 - val_mean_absolute_error: 0.1152 - val_mean_squared_error: 0.0203\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0115 - mean_absolute_error: 0.0796 - mean_squared_error: 0.0115 - val_loss: 0.0123 - val_mean_absolute_error: 0.0825 - val_mean_squared_error: 0.0123\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0116 - mean_absolute_error: 0.0795 - mean_squared_error: 0.0116 - val_loss: 0.0112 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0112\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0116 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0116 - val_loss: 0.0111 - val_mean_absolute_error: 0.0778 - val_mean_squared_error: 0.0111\n",
      "Run 2/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 72s 13ms/step - loss: 1659.9707 - mean_absolute_error: 4.8607 - mean_squared_error: 1659.9707 - val_loss: 8.3965 - val_mean_absolute_error: 2.8876 - val_mean_squared_error: 8.3965\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 56s 11ms/step - loss: 0.2120 - mean_absolute_error: 0.3483 - mean_squared_error: 0.2120 - val_loss: 103.7178 - val_mean_absolute_error: 10.1819 - val_mean_squared_error: 103.7178\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.1559 - mean_absolute_error: 0.3126 - mean_squared_error: 0.1559 - val_loss: 2.1079 - val_mean_absolute_error: 1.4470 - val_mean_squared_error: 2.1079\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 69s 14ms/step - loss: 0.1188 - mean_absolute_error: 0.2686 - mean_squared_error: 0.1188 - val_loss: 1.3001 - val_mean_absolute_error: 1.1349 - val_mean_squared_error: 1.3001\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0763 - mean_absolute_error: 0.2181 - mean_squared_error: 0.0763 - val_loss: 25.1425 - val_mean_absolute_error: 5.0131 - val_mean_squared_error: 25.1425\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 79s 16ms/step - loss: 0.0566 - mean_absolute_error: 0.1874 - mean_squared_error: 0.0566 - val_loss: 2.5152 - val_mean_absolute_error: 1.5823 - val_mean_squared_error: 2.5152\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0480 - mean_absolute_error: 0.1719 - mean_squared_error: 0.0480 - val_loss: 9.1649 - val_mean_absolute_error: 3.0255 - val_mean_squared_error: 9.1649\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0395 - mean_absolute_error: 0.1557 - mean_squared_error: 0.0395 - val_loss: 13.6554 - val_mean_absolute_error: 3.6938 - val_mean_squared_error: 13.6554\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0330 - mean_absolute_error: 0.1420 - mean_squared_error: 0.0330 - val_loss: 12.9705 - val_mean_absolute_error: 3.5996 - val_mean_squared_error: 12.9705\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0269 - mean_absolute_error: 0.1280 - mean_squared_error: 0.0269 - val_loss: 2.4370 - val_mean_absolute_error: 1.5575 - val_mean_squared_error: 2.4370\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0236 - mean_absolute_error: 0.1179 - mean_squared_error: 0.0236 - val_loss: 2.7025 - val_mean_absolute_error: 1.6406 - val_mean_squared_error: 2.7025\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0216 - mean_absolute_error: 0.1134 - mean_squared_error: 0.0216 - val_loss: 0.8552 - val_mean_absolute_error: 0.9186 - val_mean_squared_error: 0.8552\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0192 - mean_absolute_error: 0.1056 - mean_squared_error: 0.0192 - val_loss: 3.5844 - val_mean_absolute_error: 1.8904 - val_mean_squared_error: 3.5844\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0183 - mean_absolute_error: 0.1035 - mean_squared_error: 0.0183 - val_loss: 1.5402 - val_mean_absolute_error: 1.2368 - val_mean_squared_error: 1.5402\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0176 - mean_absolute_error: 0.1012 - mean_squared_error: 0.0176 - val_loss: 0.3279 - val_mean_absolute_error: 0.5630 - val_mean_squared_error: 0.3279\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0165 - mean_absolute_error: 0.0972 - mean_squared_error: 0.0165 - val_loss: 0.5840 - val_mean_absolute_error: 0.7574 - val_mean_squared_error: 0.5840\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 76s 15ms/step - loss: 0.0150 - mean_absolute_error: 0.0917 - mean_squared_error: 0.0150 - val_loss: 0.7501 - val_mean_absolute_error: 0.8598 - val_mean_squared_error: 0.7501\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 0.0142 - mean_absolute_error: 0.0892 - mean_squared_error: 0.0142 - val_loss: 0.0604 - val_mean_absolute_error: 0.2264 - val_mean_squared_error: 0.0604\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0136 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0136 - val_loss: 0.2718 - val_mean_absolute_error: 0.5111 - val_mean_squared_error: 0.2718\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 0.0133 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0133 - val_loss: 0.2238 - val_mean_absolute_error: 0.4618 - val_mean_squared_error: 0.2238\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0128 - mean_absolute_error: 0.0845 - mean_squared_error: 0.0128 - val_loss: 0.0797 - val_mean_absolute_error: 0.2643 - val_mean_squared_error: 0.0797\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 55s 11ms/step - loss: 0.0130 - mean_absolute_error: 0.0837 - mean_squared_error: 0.0130 - val_loss: 0.0135 - val_mean_absolute_error: 0.0883 - val_mean_squared_error: 0.0135\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 76s 15ms/step - loss: 0.0128 - mean_absolute_error: 0.0841 - mean_squared_error: 0.0128 - val_loss: 0.0577 - val_mean_absolute_error: 0.2194 - val_mean_squared_error: 0.0577\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0124 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0124 - val_loss: 0.0437 - val_mean_absolute_error: 0.1858 - val_mean_squared_error: 0.0437\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0118 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0118 - val_loss: 0.0202 - val_mean_absolute_error: 0.1147 - val_mean_squared_error: 0.0202\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0122 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_absolute_error: 0.0805 - val_mean_squared_error: 0.0121\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0117 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0117 - val_loss: 0.0968 - val_mean_absolute_error: 0.2946 - val_mean_squared_error: 0.0968\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 0.0119 - mean_absolute_error: 0.0796 - mean_squared_error: 0.0119 - val_loss: 0.0115 - val_mean_absolute_error: 0.0791 - val_mean_squared_error: 0.0115\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0117 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0117 - val_loss: 0.0254 - val_mean_absolute_error: 0.1332 - val_mean_squared_error: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0116 - mean_absolute_error: 0.0788 - mean_squared_error: 0.0116 - val_loss: 0.0107 - val_mean_absolute_error: 0.0750 - val_mean_squared_error: 0.0107\n",
      "Run 3/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 71s 12ms/step - loss: 1294.1368 - mean_absolute_error: 4.0440 - mean_squared_error: 1294.1368 - val_loss: 0.4775 - val_mean_absolute_error: 0.6507 - val_mean_squared_error: 0.4775\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.5145 - mean_absolute_error: 0.5629 - mean_squared_error: 0.5145 - val_loss: 0.0479 - val_mean_absolute_error: 0.1809 - val_mean_squared_error: 0.0479\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.3330 - mean_absolute_error: 0.4512 - mean_squared_error: 0.3330 - val_loss: 0.9136 - val_mean_absolute_error: 0.9464 - val_mean_squared_error: 0.9136\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.2764 - mean_absolute_error: 0.4132 - mean_squared_error: 0.2764 - val_loss: 0.7667 - val_mean_absolute_error: 0.8665 - val_mean_squared_error: 0.7667\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.1937 - mean_absolute_error: 0.3488 - mean_squared_error: 0.1937 - val_loss: 0.0893 - val_mean_absolute_error: 0.2789 - val_mean_squared_error: 0.0893\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.1508 - mean_absolute_error: 0.3072 - mean_squared_error: 0.1508 - val_loss: 0.1085 - val_mean_absolute_error: 0.3110 - val_mean_squared_error: 0.1085\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.1332 - mean_absolute_error: 0.2901 - mean_squared_error: 0.1332 - val_loss: 0.0249 - val_mean_absolute_error: 0.1301 - val_mean_squared_error: 0.0249\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0873 - mean_absolute_error: 0.2325 - mean_squared_error: 0.0873 - val_loss: 0.1015 - val_mean_absolute_error: 0.3032 - val_mean_squared_error: 0.1015\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 71s 14ms/step - loss: 0.0721 - mean_absolute_error: 0.2091 - mean_squared_error: 0.0721 - val_loss: 0.0241 - val_mean_absolute_error: 0.1275 - val_mean_squared_error: 0.0241\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0764 - mean_absolute_error: 0.2211 - mean_squared_error: 0.0764 - val_loss: 0.0112 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0112\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0613 - mean_absolute_error: 0.1974 - mean_squared_error: 0.0613 - val_loss: 0.0571 - val_mean_absolute_error: 0.2169 - val_mean_squared_error: 0.0571\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0439 - mean_absolute_error: 0.1629 - mean_squared_error: 0.0439 - val_loss: 0.0824 - val_mean_absolute_error: 0.2685 - val_mean_squared_error: 0.0824\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0449 - mean_absolute_error: 0.1658 - mean_squared_error: 0.0449 - val_loss: 0.0114 - val_mean_absolute_error: 0.0797 - val_mean_squared_error: 0.0114\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0330 - mean_absolute_error: 0.1412 - mean_squared_error: 0.0330 - val_loss: 0.0146 - val_mean_absolute_error: 0.0939 - val_mean_squared_error: 0.0146\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0316 - mean_absolute_error: 0.1377 - mean_squared_error: 0.0316 - val_loss: 0.0108 - val_mean_absolute_error: 0.0753 - val_mean_squared_error: 0.0108\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0249 - mean_absolute_error: 0.1218 - mean_squared_error: 0.0249 - val_loss: 0.0148 - val_mean_absolute_error: 0.0918 - val_mean_squared_error: 0.0148\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 70s 14ms/step - loss: 0.0220 - mean_absolute_error: 0.1148 - mean_squared_error: 0.0220 - val_loss: 0.0246 - val_mean_absolute_error: 0.1301 - val_mean_squared_error: 0.0246\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 75s 15ms/step - loss: 0.0208 - mean_absolute_error: 0.1112 - mean_squared_error: 0.0208 - val_loss: 0.0102 - val_mean_absolute_error: 0.0735 - val_mean_squared_error: 0.0102\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0193 - mean_absolute_error: 0.1066 - mean_squared_error: 0.0193 - val_loss: 0.0116 - val_mean_absolute_error: 0.0794 - val_mean_squared_error: 0.0116\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0183 - mean_absolute_error: 0.1044 - mean_squared_error: 0.0183 - val_loss: 0.0142 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.0142\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0179 - mean_absolute_error: 0.1026 - mean_squared_error: 0.0179 - val_loss: 0.0119 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0119\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0171 - mean_absolute_error: 0.1003 - mean_squared_error: 0.0171 - val_loss: 0.0140 - val_mean_absolute_error: 0.0893 - val_mean_squared_error: 0.0140\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0162 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0162 - val_loss: 0.0108 - val_mean_absolute_error: 0.0757 - val_mean_squared_error: 0.0108\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 69s 14ms/step - loss: 0.0159 - mean_absolute_error: 0.0958 - mean_squared_error: 0.0159 - val_loss: 0.0188 - val_mean_absolute_error: 0.1090 - val_mean_squared_error: 0.0188\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 76s 15ms/step - loss: 0.0152 - mean_absolute_error: 0.0940 - mean_squared_error: 0.0152 - val_loss: 0.0101 - val_mean_absolute_error: 0.0728 - val_mean_squared_error: 0.0101\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0154 - mean_absolute_error: 0.0944 - mean_squared_error: 0.0154 - val_loss: 0.0115 - val_mean_absolute_error: 0.0802 - val_mean_squared_error: 0.0115\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0146 - mean_absolute_error: 0.0917 - mean_squared_error: 0.0146 - val_loss: 0.0109 - val_mean_absolute_error: 0.0773 - val_mean_squared_error: 0.0109\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0147 - mean_absolute_error: 0.0919 - mean_squared_error: 0.0147 - val_loss: 0.0105 - val_mean_absolute_error: 0.0751 - val_mean_squared_error: 0.0105\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 0.0145 - mean_absolute_error: 0.0905 - mean_squared_error: 0.0145 - val_loss: 0.0244 - val_mean_absolute_error: 0.1293 - val_mean_squared_error: 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0139 - mean_absolute_error: 0.0895 - mean_squared_error: 0.0139 - val_loss: 0.0103 - val_mean_absolute_error: 0.0743 - val_mean_squared_error: 0.0103\n",
      "90.0 97.0\n",
      "Run 1/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 68s 12ms/step - loss: 1538.9492 - mean_absolute_error: 4.4555 - mean_squared_error: 1538.9492 - val_loss: 9.6892 - val_mean_absolute_error: 3.0965 - val_mean_squared_error: 9.6892\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 8.3401 - mean_absolute_error: 0.7191 - mean_squared_error: 8.3401 - val_loss: 3.0774 - val_mean_absolute_error: 1.6312 - val_mean_squared_error: 3.0774\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.7969 - mean_absolute_error: 0.6321 - mean_squared_error: 0.7969 - val_loss: 0.2688 - val_mean_absolute_error: 0.4554 - val_mean_squared_error: 0.2688\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.2034 - mean_absolute_error: 0.3577 - mean_squared_error: 0.2034 - val_loss: 1.3330 - val_mean_absolute_error: 1.1307 - val_mean_squared_error: 1.3330\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.1518 - mean_absolute_error: 0.3094 - mean_squared_error: 0.1518 - val_loss: 0.1237 - val_mean_absolute_error: 0.3119 - val_mean_squared_error: 0.1237\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.1071 - mean_absolute_error: 0.2600 - mean_squared_error: 0.1071 - val_loss: 0.0750 - val_mean_absolute_error: 0.2220 - val_mean_squared_error: 0.0750\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.1908 - mean_absolute_error: 0.2521 - mean_squared_error: 0.1908 - val_loss: 1.8137 - val_mean_absolute_error: 1.3291 - val_mean_squared_error: 1.8137\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0731 - mean_absolute_error: 0.2132 - mean_squared_error: 0.0731 - val_loss: 0.0275 - val_mean_absolute_error: 0.1300 - val_mean_squared_error: 0.0275\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0432 - mean_absolute_error: 0.1631 - mean_squared_error: 0.0432 - val_loss: 0.1961 - val_mean_absolute_error: 0.4251 - val_mean_squared_error: 0.1961\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0347 - mean_absolute_error: 0.1447 - mean_squared_error: 0.0347 - val_loss: 0.1127 - val_mean_absolute_error: 0.3170 - val_mean_squared_error: 0.1127\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0306 - mean_absolute_error: 0.1361 - mean_squared_error: 0.0306 - val_loss: 1.2227 - val_mean_absolute_error: 1.1001 - val_mean_squared_error: 1.2227\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0251 - mean_absolute_error: 0.1221 - mean_squared_error: 0.0251 - val_loss: 0.0352 - val_mean_absolute_error: 0.1592 - val_mean_squared_error: 0.0352\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0228 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0228 - val_loss: 0.4439 - val_mean_absolute_error: 0.6572 - val_mean_squared_error: 0.4439\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0204 - mean_absolute_error: 0.1092 - mean_squared_error: 0.0204 - val_loss: 0.6459 - val_mean_absolute_error: 0.7964 - val_mean_squared_error: 0.6459\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0192 - mean_absolute_error: 0.1052 - mean_squared_error: 0.0192 - val_loss: 0.0161 - val_mean_absolute_error: 0.0964 - val_mean_squared_error: 0.0161\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 48s 9ms/step - loss: 0.0180 - mean_absolute_error: 0.1015 - mean_squared_error: 0.0180 - val_loss: 0.0220 - val_mean_absolute_error: 0.1183 - val_mean_squared_error: 0.0220\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0173 - mean_absolute_error: 0.0989 - mean_squared_error: 0.0173 - val_loss: 0.0333 - val_mean_absolute_error: 0.1557 - val_mean_squared_error: 0.0333\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0160 - mean_absolute_error: 0.0947 - mean_squared_error: 0.0160 - val_loss: 0.2035 - val_mean_absolute_error: 0.4382 - val_mean_squared_error: 0.2035\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0155 - mean_absolute_error: 0.0928 - mean_squared_error: 0.0155 - val_loss: 0.1463 - val_mean_absolute_error: 0.3675 - val_mean_squared_error: 0.1463\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0144 - mean_absolute_error: 0.0889 - mean_squared_error: 0.0144 - val_loss: 0.0149 - val_mean_absolute_error: 0.0927 - val_mean_squared_error: 0.0149\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0145 - mean_absolute_error: 0.0891 - mean_squared_error: 0.0145 - val_loss: 0.0224 - val_mean_absolute_error: 0.1207 - val_mean_squared_error: 0.0224\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0141 - mean_absolute_error: 0.0876 - mean_squared_error: 0.0141 - val_loss: 0.0417 - val_mean_absolute_error: 0.1787 - val_mean_squared_error: 0.0417\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0140 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0140 - val_loss: 0.0240 - val_mean_absolute_error: 0.1267 - val_mean_squared_error: 0.0240\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0134 - val_loss: 0.0115 - val_mean_absolute_error: 0.0777 - val_mean_squared_error: 0.0115\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0133 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0133 - val_loss: 0.0242 - val_mean_absolute_error: 0.1260 - val_mean_squared_error: 0.0242\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0133 - mean_absolute_error: 0.0842 - mean_squared_error: 0.0133 - val_loss: 0.0134 - val_mean_absolute_error: 0.0850 - val_mean_squared_error: 0.0134\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0130 - mean_absolute_error: 0.0832 - mean_squared_error: 0.0130 - val_loss: 0.0142 - val_mean_absolute_error: 0.0895 - val_mean_squared_error: 0.0142\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0127 - mean_absolute_error: 0.0828 - mean_squared_error: 0.0127 - val_loss: 0.0162 - val_mean_absolute_error: 0.0980 - val_mean_squared_error: 0.0162\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0126 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0126 - val_loss: 0.0146 - val_mean_absolute_error: 0.0900 - val_mean_squared_error: 0.0146\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0128 - mean_absolute_error: 0.0821 - mean_squared_error: 0.0128 - val_loss: 0.0118 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0118\n",
      "Run 2/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 73s 12ms/step - loss: 1503.0846 - mean_absolute_error: 5.7991 - mean_squared_error: 1503.0846 - val_loss: 1.9130 - val_mean_absolute_error: 1.3193 - val_mean_squared_error: 1.9130\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.4025 - mean_absolute_error: 0.4865 - mean_squared_error: 0.4025 - val_loss: 0.6565 - val_mean_absolute_error: 0.7770 - val_mean_squared_error: 0.6565\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.2626 - mean_absolute_error: 0.3848 - mean_squared_error: 0.2626 - val_loss: 24.5757 - val_mean_absolute_error: 4.9536 - val_mean_squared_error: 24.5757\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.1705 - mean_absolute_error: 0.3198 - mean_squared_error: 0.1705 - val_loss: 30.6234 - val_mean_absolute_error: 5.5323 - val_mean_squared_error: 30.6234\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.1092 - mean_absolute_error: 0.2609 - mean_squared_error: 0.1092 - val_loss: 24.1462 - val_mean_absolute_error: 4.8431 - val_mean_squared_error: 24.1462\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0787 - mean_absolute_error: 0.2226 - mean_squared_error: 0.0787 - val_loss: 3.8782 - val_mean_absolute_error: 1.9658 - val_mean_squared_error: 3.8782\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0537 - mean_absolute_error: 0.1818 - mean_squared_error: 0.0537 - val_loss: 0.0966 - val_mean_absolute_error: 0.2891 - val_mean_squared_error: 0.0966\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0445 - mean_absolute_error: 0.1659 - mean_squared_error: 0.0445 - val_loss: 38.2292 - val_mean_absolute_error: 6.1819 - val_mean_squared_error: 38.2292\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0369 - mean_absolute_error: 0.1507 - mean_squared_error: 0.0369 - val_loss: 4.3564 - val_mean_absolute_error: 2.0841 - val_mean_squared_error: 4.3564\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0326 - mean_absolute_error: 0.1407 - mean_squared_error: 0.0326 - val_loss: 1.7509 - val_mean_absolute_error: 1.3175 - val_mean_squared_error: 1.7509\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0255 - mean_absolute_error: 0.1242 - mean_squared_error: 0.0255 - val_loss: 11.2216 - val_mean_absolute_error: 3.3479 - val_mean_squared_error: 11.2216\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.0233 - mean_absolute_error: 0.1175 - mean_squared_error: 0.0233 - val_loss: 0.2806 - val_mean_absolute_error: 0.5174 - val_mean_squared_error: 0.2806\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0213 - mean_absolute_error: 0.1127 - mean_squared_error: 0.0213 - val_loss: 2.0280 - val_mean_absolute_error: 1.4197 - val_mean_squared_error: 2.0280\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0191 - mean_absolute_error: 0.1052 - mean_squared_error: 0.0191 - val_loss: 17.4930 - val_mean_absolute_error: 4.1810 - val_mean_squared_error: 17.4930\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0181 - mean_absolute_error: 0.1020 - mean_squared_error: 0.0181 - val_loss: 0.0203 - val_mean_absolute_error: 0.1128 - val_mean_squared_error: 0.0203\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0168 - mean_absolute_error: 0.0987 - mean_squared_error: 0.0168 - val_loss: 2.9765 - val_mean_absolute_error: 1.7217 - val_mean_squared_error: 2.9765\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0157 - mean_absolute_error: 0.0951 - mean_squared_error: 0.0157 - val_loss: 1.1257 - val_mean_absolute_error: 1.0555 - val_mean_squared_error: 1.1257\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0148 - mean_absolute_error: 0.0912 - mean_squared_error: 0.0148 - val_loss: 0.7087 - val_mean_absolute_error: 0.8347 - val_mean_squared_error: 0.7087\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0146 - mean_absolute_error: 0.0901 - mean_squared_error: 0.0146 - val_loss: 1.1366 - val_mean_absolute_error: 1.0606 - val_mean_squared_error: 1.1366\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0139 - mean_absolute_error: 0.0884 - mean_squared_error: 0.0139 - val_loss: 1.3422 - val_mean_absolute_error: 1.1536 - val_mean_squared_error: 1.3422\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0137 - mean_absolute_error: 0.0873 - mean_squared_error: 0.0137 - val_loss: 1.7384 - val_mean_absolute_error: 1.3141 - val_mean_squared_error: 1.7384\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0862 - mean_squared_error: 0.0134 - val_loss: 0.0163 - val_mean_absolute_error: 0.0989 - val_mean_squared_error: 0.0163\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0131 - mean_absolute_error: 0.0854 - mean_squared_error: 0.0131 - val_loss: 0.1297 - val_mean_absolute_error: 0.3454 - val_mean_squared_error: 0.1297\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0130 - mean_absolute_error: 0.0848 - mean_squared_error: 0.0130 - val_loss: 0.0324 - val_mean_absolute_error: 0.1521 - val_mean_squared_error: 0.0324\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0131 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0131 - val_loss: 0.0126 - val_mean_absolute_error: 0.0829 - val_mean_squared_error: 0.0126\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0125 - mean_absolute_error: 0.0833 - mean_squared_error: 0.0125 - val_loss: 0.0706 - val_mean_absolute_error: 0.2459 - val_mean_squared_error: 0.0706\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0126 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0126 - val_loss: 0.0638 - val_mean_absolute_error: 0.2320 - val_mean_squared_error: 0.0638\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 54s 11ms/step - loss: 0.0125 - mean_absolute_error: 0.0827 - mean_squared_error: 0.0125 - val_loss: 0.1190 - val_mean_absolute_error: 0.3295 - val_mean_squared_error: 0.1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0125 - mean_absolute_error: 0.0825 - mean_squared_error: 0.0125 - val_loss: 0.0207 - val_mean_absolute_error: 0.1156 - val_mean_squared_error: 0.0207\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0123 - mean_absolute_error: 0.0821 - mean_squared_error: 0.0123 - val_loss: 0.0332 - val_mean_absolute_error: 0.1560 - val_mean_squared_error: 0.0332\n",
      "Run 3/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 68s 12ms/step - loss: 1596.2788 - mean_absolute_error: 4.3856 - mean_squared_error: 1596.2788 - val_loss: 0.5515 - val_mean_absolute_error: 0.6759 - val_mean_squared_error: 0.5515\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.4659 - mean_absolute_error: 0.4863 - mean_squared_error: 0.4659 - val_loss: 1109.0078 - val_mean_absolute_error: 33.2999 - val_mean_squared_error: 1109.0078\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.3502 - mean_absolute_error: 0.4700 - mean_squared_error: 0.3502 - val_loss: 0.4052 - val_mean_absolute_error: 0.6146 - val_mean_squared_error: 0.4052\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.1852 - mean_absolute_error: 0.3324 - mean_squared_error: 0.1852 - val_loss: 0.0191 - val_mean_absolute_error: 0.1062 - val_mean_squared_error: 0.0191\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0895 - mean_absolute_error: 0.2355 - mean_squared_error: 0.0895 - val_loss: 0.3034 - val_mean_absolute_error: 0.5376 - val_mean_squared_error: 0.3034\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0670 - mean_absolute_error: 0.1988 - mean_squared_error: 0.0670 - val_loss: 0.9498 - val_mean_absolute_error: 0.9680 - val_mean_squared_error: 0.9498\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0509 - mean_absolute_error: 0.1773 - mean_squared_error: 0.0509 - val_loss: 0.2023 - val_mean_absolute_error: 0.4371 - val_mean_squared_error: 0.2023\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0360 - mean_absolute_error: 0.1486 - mean_squared_error: 0.0360 - val_loss: 0.1258 - val_mean_absolute_error: 0.3381 - val_mean_squared_error: 0.1258\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0300 - mean_absolute_error: 0.1352 - mean_squared_error: 0.0300 - val_loss: 0.2026 - val_mean_absolute_error: 0.4385 - val_mean_squared_error: 0.2026\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0252 - mean_absolute_error: 0.1236 - mean_squared_error: 0.0252 - val_loss: 0.1118 - val_mean_absolute_error: 0.3197 - val_mean_squared_error: 0.1118\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0228 - mean_absolute_error: 0.1170 - mean_squared_error: 0.0228 - val_loss: 0.0403 - val_mean_absolute_error: 0.1750 - val_mean_squared_error: 0.0403\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0189 - mean_absolute_error: 0.1063 - mean_squared_error: 0.0189 - val_loss: 0.2514 - val_mean_absolute_error: 0.4906 - val_mean_squared_error: 0.2514\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0164 - mean_absolute_error: 0.0972 - mean_squared_error: 0.0164 - val_loss: 0.0997 - val_mean_absolute_error: 0.3005 - val_mean_squared_error: 0.0997\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0160 - mean_absolute_error: 0.0968 - mean_squared_error: 0.0160 - val_loss: 0.0523 - val_mean_absolute_error: 0.2062 - val_mean_squared_error: 0.0523\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0152 - mean_absolute_error: 0.0935 - mean_squared_error: 0.0152 - val_loss: 0.0183 - val_mean_absolute_error: 0.1083 - val_mean_squared_error: 0.0183\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0141 - mean_absolute_error: 0.0894 - mean_squared_error: 0.0141 - val_loss: 0.1914 - val_mean_absolute_error: 0.4264 - val_mean_squared_error: 0.1914\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0135 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0135 - val_loss: 0.1578 - val_mean_absolute_error: 0.3848 - val_mean_squared_error: 0.1578\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0128 - mean_absolute_error: 0.0851 - mean_squared_error: 0.0128 - val_loss: 0.1003 - val_mean_absolute_error: 0.3012 - val_mean_squared_error: 0.1003\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0125 - mean_absolute_error: 0.0843 - mean_squared_error: 0.0125 - val_loss: 0.0514 - val_mean_absolute_error: 0.2049 - val_mean_squared_error: 0.0514\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0122 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0122 - val_loss: 0.0114 - val_mean_absolute_error: 0.0795 - val_mean_squared_error: 0.0114\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.0120 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0120 - val_loss: 0.0971 - val_mean_absolute_error: 0.2963 - val_mean_squared_error: 0.0971\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.0116 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0116 - val_loss: 0.0152 - val_mean_absolute_error: 0.0961 - val_mean_squared_error: 0.0152\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 78s 16ms/step - loss: 0.0116 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0116 - val_loss: 0.0203 - val_mean_absolute_error: 0.1160 - val_mean_squared_error: 0.0203\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 0.0113 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0113 - val_loss: 0.0185 - val_mean_absolute_error: 0.1092 - val_mean_squared_error: 0.0185\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0111 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0111 - val_loss: 0.0105 - val_mean_absolute_error: 0.0751 - val_mean_squared_error: 0.0105\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0109 - mean_absolute_error: 0.0770 - mean_squared_error: 0.0109 - val_loss: 0.0177 - val_mean_absolute_error: 0.1044 - val_mean_squared_error: 0.0177\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0108 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0108 - val_loss: 0.0109 - val_mean_absolute_error: 0.0774 - val_mean_squared_error: 0.0109\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0108 - mean_absolute_error: 0.0764 - mean_squared_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0106\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0107 - mean_absolute_error: 0.0761 - mean_squared_error: 0.0107 - val_loss: 0.0106 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0106\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0107 - mean_absolute_error: 0.0762 - mean_squared_error: 0.0107 - val_loss: 0.0108 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0108\n",
      "90.0 106.0\n",
      "Run 1/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 64s 11ms/step - loss: 2358.2131 - mean_absolute_error: 6.3971 - mean_squared_error: 2358.2131 - val_loss: 0.2689 - val_mean_absolute_error: 0.4295 - val_mean_squared_error: 0.2689\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 2.5124 - mean_absolute_error: 0.6360 - mean_squared_error: 2.5124 - val_loss: 140.7943 - val_mean_absolute_error: 11.8547 - val_mean_squared_error: 140.7943\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.4518 - mean_absolute_error: 0.3463 - mean_squared_error: 0.4518 - val_loss: 222.5624 - val_mean_absolute_error: 7.3294 - val_mean_squared_error: 222.5624\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.1996 - mean_absolute_error: 0.3328 - mean_squared_error: 0.1996 - val_loss: 0.0267 - val_mean_absolute_error: 0.1290 - val_mean_squared_error: 0.0267\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0867 - mean_absolute_error: 0.2305 - mean_squared_error: 0.0867 - val_loss: 0.1600 - val_mean_absolute_error: 0.3852 - val_mean_squared_error: 0.1600\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0666 - mean_absolute_error: 0.2023 - mean_squared_error: 0.0666 - val_loss: 0.2191 - val_mean_absolute_error: 0.4559 - val_mean_squared_error: 0.2191\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0553 - mean_absolute_error: 0.1843 - mean_squared_error: 0.0553 - val_loss: 0.0332 - val_mean_absolute_error: 0.1530 - val_mean_squared_error: 0.0332\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0439 - mean_absolute_error: 0.1650 - mean_squared_error: 0.0439 - val_loss: 0.4793 - val_mean_absolute_error: 0.6841 - val_mean_squared_error: 0.4793\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0339 - mean_absolute_error: 0.1442 - mean_squared_error: 0.0339 - val_loss: 0.4082 - val_mean_absolute_error: 0.6295 - val_mean_squared_error: 0.4082\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0422 - mean_absolute_error: 0.1626 - mean_squared_error: 0.0422 - val_loss: 0.0455 - val_mean_absolute_error: 0.1894 - val_mean_squared_error: 0.0455\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0299 - mean_absolute_error: 0.1340 - mean_squared_error: 0.0299 - val_loss: 0.2068 - val_mean_absolute_error: 0.4424 - val_mean_squared_error: 0.2068\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0252 - mean_absolute_error: 0.1235 - mean_squared_error: 0.0252 - val_loss: 0.0146 - val_mean_absolute_error: 0.0913 - val_mean_squared_error: 0.0146\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0212 - mean_absolute_error: 0.1130 - mean_squared_error: 0.0212 - val_loss: 0.0843 - val_mean_absolute_error: 0.2728 - val_mean_squared_error: 0.0843\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0192 - mean_absolute_error: 0.1067 - mean_squared_error: 0.0192 - val_loss: 0.0684 - val_mean_absolute_error: 0.2410 - val_mean_squared_error: 0.0684\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0175 - mean_absolute_error: 0.1014 - mean_squared_error: 0.0175 - val_loss: 0.0124 - val_mean_absolute_error: 0.0835 - val_mean_squared_error: 0.0124\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0171 - mean_absolute_error: 0.0998 - mean_squared_error: 0.0171 - val_loss: 0.0145 - val_mean_absolute_error: 0.0910 - val_mean_squared_error: 0.0145\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0162 - mean_absolute_error: 0.0967 - mean_squared_error: 0.0162 - val_loss: 0.0383 - val_mean_absolute_error: 0.1696 - val_mean_squared_error: 0.0383\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0151 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0151 - val_loss: 0.0115 - val_mean_absolute_error: 0.0785 - val_mean_squared_error: 0.0115\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0149 - mean_absolute_error: 0.0925 - mean_squared_error: 0.0149 - val_loss: 0.0165 - val_mean_absolute_error: 0.0986 - val_mean_squared_error: 0.0165\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0144 - mean_absolute_error: 0.0905 - mean_squared_error: 0.0144 - val_loss: 0.0156 - val_mean_absolute_error: 0.0949 - val_mean_squared_error: 0.0156\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0138 - mean_absolute_error: 0.0882 - mean_squared_error: 0.0138 - val_loss: 0.0109 - val_mean_absolute_error: 0.0765 - val_mean_squared_error: 0.0109\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0134 - mean_absolute_error: 0.0871 - mean_squared_error: 0.0134 - val_loss: 0.0219 - val_mean_absolute_error: 0.1186 - val_mean_squared_error: 0.0219\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0131 - mean_absolute_error: 0.0863 - mean_squared_error: 0.0131 - val_loss: 0.0212 - val_mean_absolute_error: 0.1162 - val_mean_squared_error: 0.0212\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.0129 - mean_absolute_error: 0.0850 - mean_squared_error: 0.0129 - val_loss: 0.0114 - val_mean_absolute_error: 0.0789 - val_mean_squared_error: 0.0114\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 59s 12ms/step - loss: 0.0128 - mean_absolute_error: 0.0847 - mean_squared_error: 0.0128 - val_loss: 0.0112 - val_mean_absolute_error: 0.0776 - val_mean_squared_error: 0.0112\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0128 - mean_absolute_error: 0.0844 - mean_squared_error: 0.0128 - val_loss: 0.0142 - val_mean_absolute_error: 0.0894 - val_mean_squared_error: 0.0142\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0126 - mean_absolute_error: 0.0834 - mean_squared_error: 0.0126 - val_loss: 0.0116 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0123 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0123 - val_loss: 0.0112 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0112\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0121 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0121 - val_loss: 0.0111 - val_mean_absolute_error: 0.0776 - val_mean_squared_error: 0.0111\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0122 - mean_absolute_error: 0.0820 - mean_squared_error: 0.0122 - val_loss: 0.0114 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0114\n",
      "Run 2/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 65s 11ms/step - loss: 2259.7034 - mean_absolute_error: 5.9770 - mean_squared_error: 2259.7034 - val_loss: 0.1807 - val_mean_absolute_error: 0.3225 - val_mean_squared_error: 0.1807\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.3686 - mean_absolute_error: 0.4767 - mean_squared_error: 0.3686 - val_loss: 1.3525 - val_mean_absolute_error: 1.1511 - val_mean_squared_error: 1.3525\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.1862 - mean_absolute_error: 0.3427 - mean_squared_error: 0.1862 - val_loss: 0.8942 - val_mean_absolute_error: 0.9370 - val_mean_squared_error: 0.8942\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.1206 - mean_absolute_error: 0.2748 - mean_squared_error: 0.1206 - val_loss: 10.8046 - val_mean_absolute_error: 3.2845 - val_mean_squared_error: 10.8046\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0745 - mean_absolute_error: 0.2159 - mean_squared_error: 0.0745 - val_loss: 0.8067 - val_mean_absolute_error: 0.8906 - val_mean_squared_error: 0.8067\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0600 - mean_absolute_error: 0.1896 - mean_squared_error: 0.0600 - val_loss: 22.4129 - val_mean_absolute_error: 4.7325 - val_mean_squared_error: 22.4129\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0615 - mean_absolute_error: 0.1943 - mean_squared_error: 0.0615 - val_loss: 3.3162 - val_mean_absolute_error: 1.8176 - val_mean_squared_error: 3.3162\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0491 - mean_absolute_error: 0.1762 - mean_squared_error: 0.0491 - val_loss: 7.6600 - val_mean_absolute_error: 2.7652 - val_mean_squared_error: 7.6600\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0371 - mean_absolute_error: 0.1514 - mean_squared_error: 0.0371 - val_loss: 13.4680 - val_mean_absolute_error: 3.6683 - val_mean_squared_error: 13.4680\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0293 - mean_absolute_error: 0.1328 - mean_squared_error: 0.0293 - val_loss: 1.3557 - val_mean_absolute_error: 1.1593 - val_mean_squared_error: 1.3557\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 58s 12ms/step - loss: 0.0244 - mean_absolute_error: 0.1217 - mean_squared_error: 0.0244 - val_loss: 0.4557 - val_mean_absolute_error: 0.6663 - val_mean_squared_error: 0.4557\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0214 - mean_absolute_error: 0.1127 - mean_squared_error: 0.0214 - val_loss: 0.0291 - val_mean_absolute_error: 0.1390 - val_mean_squared_error: 0.0291\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0227 - mean_absolute_error: 0.1171 - mean_squared_error: 0.0227 - val_loss: 0.0579 - val_mean_absolute_error: 0.2125 - val_mean_squared_error: 0.0579\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0224 - mean_absolute_error: 0.1162 - mean_squared_error: 0.0224 - val_loss: 2.2123 - val_mean_absolute_error: 1.4829 - val_mean_squared_error: 2.2123\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0203 - mean_absolute_error: 0.1100 - mean_squared_error: 0.0203 - val_loss: 0.9965 - val_mean_absolute_error: 0.9916 - val_mean_squared_error: 0.9965\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0185 - mean_absolute_error: 0.1040 - mean_squared_error: 0.0185 - val_loss: 0.0219 - val_mean_absolute_error: 0.1170 - val_mean_squared_error: 0.0219\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0182 - mean_absolute_error: 0.1037 - mean_squared_error: 0.0182 - val_loss: 0.0490 - val_mean_absolute_error: 0.1929 - val_mean_squared_error: 0.0490\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0177 - mean_absolute_error: 0.1023 - mean_squared_error: 0.0177 - val_loss: 0.0155 - val_mean_absolute_error: 0.0959 - val_mean_squared_error: 0.0155\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0170 - mean_absolute_error: 0.1000 - mean_squared_error: 0.0170 - val_loss: 0.4536 - val_mean_absolute_error: 0.6634 - val_mean_squared_error: 0.4536\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0161 - mean_absolute_error: 0.0969 - mean_squared_error: 0.0161 - val_loss: 0.2563 - val_mean_absolute_error: 0.4934 - val_mean_squared_error: 0.2563\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0153 - mean_absolute_error: 0.0941 - mean_squared_error: 0.0153 - val_loss: 0.2429 - val_mean_absolute_error: 0.4795 - val_mean_squared_error: 0.2429\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0153 - mean_absolute_error: 0.0939 - mean_squared_error: 0.0153 - val_loss: 0.0347 - val_mean_absolute_error: 0.1572 - val_mean_squared_error: 0.0347\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0148 - mean_absolute_error: 0.0927 - mean_squared_error: 0.0148 - val_loss: 0.0402 - val_mean_absolute_error: 0.1722 - val_mean_squared_error: 0.0402\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 53s 10ms/step - loss: 0.0149 - mean_absolute_error: 0.0925 - mean_squared_error: 0.0149 - val_loss: 0.0211 - val_mean_absolute_error: 0.1148 - val_mean_squared_error: 0.0211\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0147 - mean_absolute_error: 0.0916 - mean_squared_error: 0.0147 - val_loss: 0.0300 - val_mean_absolute_error: 0.1433 - val_mean_squared_error: 0.0300\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0143 - mean_absolute_error: 0.0910 - mean_squared_error: 0.0143 - val_loss: 0.0299 - val_mean_absolute_error: 0.1428 - val_mean_squared_error: 0.0299\n",
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0143 - mean_absolute_error: 0.0909 - mean_squared_error: 0.0143 - val_loss: 0.0173 - val_mean_absolute_error: 0.1014 - val_mean_squared_error: 0.0173\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0144 - mean_absolute_error: 0.0907 - mean_squared_error: 0.0144 - val_loss: 0.0192 - val_mean_absolute_error: 0.1080 - val_mean_squared_error: 0.0192\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0142 - mean_absolute_error: 0.0903 - mean_squared_error: 0.0142 - val_loss: 0.0178 - val_mean_absolute_error: 0.1036 - val_mean_squared_error: 0.0178\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0144 - mean_absolute_error: 0.0907 - mean_squared_error: 0.0144 - val_loss: 0.0173 - val_mean_absolute_error: 0.1013 - val_mean_squared_error: 0.0173\n",
      "Run 3/3\n",
      "Epoch 1/30\n",
      "Current Learning rate: 0.001\n",
      "5000/5000 [==============================] - 64s 11ms/step - loss: 1375.5563 - mean_absolute_error: 4.1352 - mean_squared_error: 1375.5563 - val_loss: 5.2270 - val_mean_absolute_error: 2.0802 - val_mean_squared_error: 5.2270\n",
      "Epoch 2/30\n",
      "Current Learning rate: 0.0007943282347242815\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.6307 - mean_absolute_error: 0.5917 - mean_squared_error: 0.6307 - val_loss: 3.0618 - val_mean_absolute_error: 1.7410 - val_mean_squared_error: 3.0618\n",
      "Epoch 3/30\n",
      "Current Learning rate: 0.0006309573444801933\n",
      "5000/5000 [==============================] - 66s 13ms/step - loss: 0.3614 - mean_absolute_error: 0.4741 - mean_squared_error: 0.3614 - val_loss: 28.3762 - val_mean_absolute_error: 5.3215 - val_mean_squared_error: 28.3762\n",
      "Epoch 4/30\n",
      "Current Learning rate: 0.0005011872336272722\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.2493 - mean_absolute_error: 0.3955 - mean_squared_error: 0.2493 - val_loss: 0.0821 - val_mean_absolute_error: 0.2612 - val_mean_squared_error: 0.0821\n",
      "Epoch 5/30\n",
      "Current Learning rate: 0.00039810717055349724\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.1693 - mean_absolute_error: 0.3263 - mean_squared_error: 0.1693 - val_loss: 3.0345 - val_mean_absolute_error: 1.7356 - val_mean_squared_error: 3.0345\n",
      "Epoch 6/30\n",
      "Current Learning rate: 0.00031622776601683794\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.1141 - mean_absolute_error: 0.2688 - mean_squared_error: 0.1141 - val_loss: 0.2203 - val_mean_absolute_error: 0.3940 - val_mean_squared_error: 0.2203\n",
      "Epoch 7/30\n",
      "Current Learning rate: 0.000251188643150958\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0741 - mean_absolute_error: 0.2156 - mean_squared_error: 0.0741 - val_loss: 1.2028 - val_mean_absolute_error: 1.0787 - val_mean_squared_error: 1.2028\n",
      "Epoch 8/30\n",
      "Current Learning rate: 0.00019952623149688796\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0510 - mean_absolute_error: 0.1769 - mean_squared_error: 0.0510 - val_loss: 3.3079 - val_mean_absolute_error: 1.8145 - val_mean_squared_error: 3.3079\n",
      "Epoch 9/30\n",
      "Current Learning rate: 0.00015848931924611134\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0415 - mean_absolute_error: 0.1605 - mean_squared_error: 0.0415 - val_loss: 0.3453 - val_mean_absolute_error: 0.5686 - val_mean_squared_error: 0.3453\n",
      "Epoch 10/30\n",
      "Current Learning rate: 0.00012589254117941674\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0316 - mean_absolute_error: 0.1386 - mean_squared_error: 0.0316 - val_loss: 2.2729 - val_mean_absolute_error: 1.5037 - val_mean_squared_error: 2.2729\n",
      "Epoch 11/30\n",
      "Current Learning rate: 0.00010000000000000002\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0277 - mean_absolute_error: 0.1293 - mean_squared_error: 0.0277 - val_loss: 3.3793 - val_mean_absolute_error: 1.8351 - val_mean_squared_error: 3.3793\n",
      "Epoch 12/30\n",
      "Current Learning rate: 7.943282347242817e-05\n",
      "5000/5000 [==============================] - 48s 10ms/step - loss: 0.0240 - mean_absolute_error: 0.1191 - mean_squared_error: 0.0240 - val_loss: 15.6757 - val_mean_absolute_error: 3.9578 - val_mean_squared_error: 15.6757\n",
      "Epoch 13/30\n",
      "Current Learning rate: 6.309573444801932e-05\n",
      "5000/5000 [==============================] - 65s 13ms/step - loss: 0.0213 - mean_absolute_error: 0.1117 - mean_squared_error: 0.0213 - val_loss: 0.5501 - val_mean_absolute_error: 0.7342 - val_mean_squared_error: 0.5501\n",
      "Epoch 14/30\n",
      "Current Learning rate: 5.011872336272723e-05\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0189 - mean_absolute_error: 0.1051 - mean_squared_error: 0.0189 - val_loss: 1.0782 - val_mean_absolute_error: 1.0330 - val_mean_squared_error: 1.0782\n",
      "Epoch 15/30\n",
      "Current Learning rate: 3.981071705534972e-05\n",
      "5000/5000 [==============================] - 64s 13ms/step - loss: 0.0177 - mean_absolute_error: 0.1007 - mean_squared_error: 0.0177 - val_loss: 0.0352 - val_mean_absolute_error: 0.1567 - val_mean_squared_error: 0.0352\n",
      "Epoch 16/30\n",
      "Current Learning rate: 3.1622776601683795e-05\n",
      "5000/5000 [==============================] - 47s 9ms/step - loss: 0.0167 - mean_absolute_error: 0.0978 - mean_squared_error: 0.0167 - val_loss: 0.1658 - val_mean_absolute_error: 0.3954 - val_mean_squared_error: 0.1658\n",
      "Epoch 17/30\n",
      "Current Learning rate: 2.51188643150958e-05\n",
      "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0155 - mean_absolute_error: 0.0936 - mean_squared_error: 0.0155 - val_loss: 0.2554 - val_mean_absolute_error: 0.4942 - val_mean_squared_error: 0.2554\n",
      "Epoch 18/30\n",
      "Current Learning rate: 1.99526231496888e-05\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0145 - mean_absolute_error: 0.0902 - mean_squared_error: 0.0145 - val_loss: 0.0225 - val_mean_absolute_error: 0.1201 - val_mean_squared_error: 0.0225\n",
      "Epoch 19/30\n",
      "Current Learning rate: 1.5848931924611138e-05\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0139 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0139 - val_loss: 0.0442 - val_mean_absolute_error: 0.1864 - val_mean_squared_error: 0.0442\n",
      "Epoch 20/30\n",
      "Current Learning rate: 1.2589254117941675e-05\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0133 - mean_absolute_error: 0.0859 - mean_squared_error: 0.0133 - val_loss: 0.0111 - val_mean_absolute_error: 0.0765 - val_mean_squared_error: 0.0111\n",
      "Epoch 21/30\n",
      "Current Learning rate: 1.0000000000000003e-05\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0131 - mean_absolute_error: 0.0845 - mean_squared_error: 0.0131 - val_loss: 0.0403 - val_mean_absolute_error: 0.1765 - val_mean_squared_error: 0.0403\n",
      "Epoch 22/30\n",
      "Current Learning rate: 7.943282347242817e-06\n",
      "5000/5000 [==============================] - 50s 10ms/step - loss: 0.0128 - mean_absolute_error: 0.0834 - mean_squared_error: 0.0128 - val_loss: 0.0217 - val_mean_absolute_error: 0.1181 - val_mean_squared_error: 0.0217\n",
      "Epoch 23/30\n",
      "Current Learning rate: 6.309573444801935e-06\n",
      "5000/5000 [==============================] - 60s 12ms/step - loss: 0.0125 - mean_absolute_error: 0.0823 - mean_squared_error: 0.0125 - val_loss: 0.0319 - val_mean_absolute_error: 0.1513 - val_mean_squared_error: 0.0319\n",
      "Epoch 24/30\n",
      "Current Learning rate: 5.011872336272722e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0123 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0123 - val_loss: 0.0130 - val_mean_absolute_error: 0.0861 - val_mean_squared_error: 0.0130\n",
      "Epoch 25/30\n",
      "Current Learning rate: 3.981071705534972e-06\n",
      "5000/5000 [==============================] - 61s 12ms/step - loss: 0.0122 - mean_absolute_error: 0.0811 - mean_squared_error: 0.0122 - val_loss: 0.0349 - val_mean_absolute_error: 0.1603 - val_mean_squared_error: 0.0349\n",
      "Epoch 26/30\n",
      "Current Learning rate: 3.1622776601683788e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0120 - mean_absolute_error: 0.0807 - mean_squared_error: 0.0120 - val_loss: 0.0114 - val_mean_absolute_error: 0.0786 - val_mean_squared_error: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "Current Learning rate: 2.5118864315095793e-06\n",
      "5000/5000 [==============================] - 62s 12ms/step - loss: 0.0120 - mean_absolute_error: 0.0802 - mean_squared_error: 0.0120 - val_loss: 0.0129 - val_mean_absolute_error: 0.0854 - val_mean_squared_error: 0.0129\n",
      "Epoch 28/30\n",
      "Current Learning rate: 1.9952623149688796e-06\n",
      "5000/5000 [==============================] - 53s 11ms/step - loss: 0.0120 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0120 - val_loss: 0.0108 - val_mean_absolute_error: 0.0752 - val_mean_squared_error: 0.0108\n",
      "Epoch 29/30\n",
      "Current Learning rate: 1.5848931924611134e-06\n",
      "5000/5000 [==============================] - 63s 13ms/step - loss: 0.0117 - mean_absolute_error: 0.0792 - mean_squared_error: 0.0117 - val_loss: 0.0110 - val_mean_absolute_error: 0.0761 - val_mean_squared_error: 0.0110\n",
      "Epoch 30/30\n",
      "Current Learning rate: 1.2589254117941674e-06\n",
      "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0118 - mean_absolute_error: 0.0789 - mean_squared_error: 0.0118 - val_loss: 0.0115 - val_mean_absolute_error: 0.0794 - val_mean_squared_error: 0.0115\n"
     ]
    }
   ],
   "source": [
    "num_runs = 3  # Number of times to run the model\n",
    "\n",
    "df = pd.read_hdf(file_list[0], key=None)\n",
    "\n",
    "unique_mass = df['A'].unique()\n",
    "# Assuming you have already loaded the DataFrame 'df'\n",
    "\n",
    "# Step 1: Group by 'A' (mass) and 'Z' (energy) and count the occurrences\n",
    "grouped = df.groupby(['A', 'Z']).size().reset_index(name='count')\n",
    "\n",
    "mass_subgroups = grouped.groupby('A')\n",
    "\n",
    "#  133. 140. 149.\n",
    "\n",
    "\n",
    "# 90.0 88.0\n",
    "# 90.0 97.0\n",
    "# 90.0 106.0\n",
    "\n",
    "\n",
    "mass = 90.0\n",
    "energy = 88.0\n",
    "\n",
    "print(mass,energy)\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}/{num_runs}\")\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "\n",
    "    MC_path = f\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Trainings/model_{mass}_{energy}_checkpoint_{run + 1}.h5\"\n",
    "    MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    "    )\n",
    "\n",
    "    callbacks = [MC,LRS,CSV]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x=dataset_train, validation_data = dataset_val, steps_per_epoch=steps_per_epoch, epochs=num_epochs,callbacks=callbacks)        \n",
    "\n",
    "    \n",
    "    \n",
    "mass = 90.0\n",
    "energy = 97.0\n",
    "\n",
    "print(mass,energy)\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}/{num_runs}\")\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "\n",
    "    MC_path = f\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Trainings/model_{mass}_{energy}_checkpoint_{run + 1}.h5\"\n",
    "    MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    "    )\n",
    "\n",
    "    callbacks = [MC,LRS,CSV]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x=dataset_train, validation_data = dataset_val, steps_per_epoch=steps_per_epoch, epochs=num_epochs,callbacks=callbacks)        \n",
    "    \n",
    "    \n",
    "mass = 90.0\n",
    "energy = 106.0\n",
    "\n",
    "print(mass,energy)\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}/{num_runs}\")\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(loss=loss_function[lf], optimizer = keras.optimizers.Adam(initial_lr), metrics=['mean_absolute_error','mean_squared_error'])\n",
    "\n",
    "    MC_path = f\"C:/Users/steve/OneDrive/Bureaublad/Studies/Thesis/Trainings/model_{mass}_{energy}_checkpoint_{run + 1}.h5\"\n",
    "    MC = ModelCheckpoint(\n",
    "    filepath=MC_path,  # Filepath to save the model weights\n",
    "    monitor='val_loss',  # Quantity to monitor (e.g., validation loss)\n",
    "    save_best_only=True,  # Save only the best model based on the monitored quantity\n",
    "    save_weights_only=True  # Save only the model weights, not the entire model\n",
    "    )\n",
    "\n",
    "    callbacks = [MC,LRS,CSV]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x=dataset_train, validation_data = dataset_val, steps_per_epoch=steps_per_epoch, epochs=num_epochs,callbacks=callbacks)        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef46486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original panda file: 10055\n",
      "100.0 108\n",
      "Number of deleted rows: 17\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 34\n",
      "Number of deleted rows: 104\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 41\n",
      "Number of deleted rows: 94\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 48\n",
      "Number of deleted rows: 73\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 58\n",
      "Number of deleted rows: 303\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 68\n",
      "Number of deleted rows: 390\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 78\n",
      "Number of deleted rows: 302\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 88\n",
      "Number of deleted rows: 85\n",
      "\n",
      "Size of original panda file: 10055\n",
      "100.0 98\n",
      "Number of deleted rows: 170\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 22\n",
      "Number of deleted rows: 59\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 30\n",
      "Number of deleted rows: 177\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 38\n",
      "Number of deleted rows: 206\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 46\n",
      "Number of deleted rows: 75\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 54\n",
      "Number of deleted rows: 56\n",
      "\n",
      "Size of original panda file: 10055\n",
      "104.0 62\n",
      "Number of deleted rows: 42\n",
      "\n",
      "Size of original panda file: 10055\n",
      "105.0 103\n",
      "Number of deleted rows: 89\n",
      "\n",
      "Size of original panda file: 10055\n",
      "105.0 61\n",
      "Number of deleted rows: 288\n",
      "\n",
      "Size of original panda file: 10055\n",
      "105.0 72\n",
      "Number of deleted rows: 382\n",
      "\n",
      "Size of original panda file: 10055\n",
      "105.0 82\n",
      "Number of deleted rows: 289\n",
      "\n",
      "Size of original panda file: 10055\n",
      "105.0 93\n",
      "Number of deleted rows: 70\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 47\n",
      "Number of deleted rows: 3\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 63\n",
      "Number of deleted rows: 9\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 64\n",
      "Number of deleted rows: 53\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 75\n",
      "Number of deleted rows: 71\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 86\n",
      "Number of deleted rows: 46\n",
      "\n",
      "Size of original panda file: 10055\n",
      "110.0 97\n",
      "Number of deleted rows: 6\n",
      "\n",
      "Size of original panda file: 10055\n",
      "127.0 52\n",
      "Number of deleted rows: 45\n",
      "\n",
      "Size of original panda file: 10055\n",
      "127.0 61\n",
      "Number of deleted rows: 44\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 28\n",
      "Number of deleted rows: 38\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 38\n",
      "Number of deleted rows: 200\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 48\n",
      "Number of deleted rows: 333\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 58\n",
      "Number of deleted rows: 149\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 68\n",
      "Number of deleted rows: 147\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 76\n",
      "Number of deleted rows: 171\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 78\n",
      "Number of deleted rows: 60\n",
      "\n",
      "Size of original panda file: 10055\n",
      "130.0 89\n",
      "Number of deleted rows: 21\n",
      "\n",
      "Size of original panda file: 10055\n",
      "133.0 55\n",
      "Number of deleted rows: 108\n",
      "\n",
      "Size of original panda file: 10055\n",
      "133.0 65\n",
      "Number of deleted rows: 96\n",
      "\n",
      "Size of original panda file: 10055\n",
      "135.0 79\n",
      "Number of deleted rows: 197\n",
      "\n",
      "Size of original panda file: 10055\n",
      "136.0 38\n",
      "Number of deleted rows: 57\n",
      "\n",
      "Size of original panda file: 10055\n",
      "136.0 48\n",
      "Number of deleted rows: 113\n",
      "\n",
      "Size of original panda file: 10055\n",
      "136.0 58\n",
      "Number of deleted rows: 158\n",
      "\n",
      "Size of original panda file: 10055\n",
      "136.0 68\n",
      "Number of deleted rows: 112\n",
      "\n",
      "Size of original panda file: 10055\n",
      "136.0 78\n",
      "Number of deleted rows: 95\n",
      "\n",
      "Size of original panda file: 10055\n",
      "140.0 48\n",
      "Number of deleted rows: 285\n",
      "\n",
      "Size of original panda file: 10055\n",
      "140.0 58\n",
      "Number of deleted rows: 452\n",
      "\n",
      "Size of original panda file: 10055\n",
      "140.0 68\n",
      "Number of deleted rows: 228\n",
      "\n",
      "Size of original panda file: 10055\n",
      "143.0 31\n",
      "Number of deleted rows: 101\n",
      "\n",
      "Size of original panda file: 10055\n",
      "143.0 42\n",
      "Number of deleted rows: 525\n",
      "\n",
      "Size of original panda file: 10055\n",
      "143.0 53\n",
      "Number of deleted rows: 970\n",
      "\n",
      "Size of original panda file: 10055\n",
      "143.0 64\n",
      "Number of deleted rows: 175\n",
      "\n",
      "Size of original panda file: 10055\n",
      "149.0 42\n",
      "Number of deleted rows: 31\n",
      "\n",
      "Size of original panda file: 10055\n",
      "149.0 53\n",
      "Number of deleted rows: 37\n",
      "\n",
      "Size of original panda file: 10055\n",
      "80.0 94\n",
      "Number of deleted rows: 1\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 100\n",
      "Number of deleted rows: 5\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 49\n",
      "Number of deleted rows: 23\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 58\n",
      "Number of deleted rows: 22\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 66\n",
      "Number of deleted rows: 13\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 75\n",
      "Number of deleted rows: 3\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 83\n",
      "Number of deleted rows: 16\n",
      "\n",
      "Size of original panda file: 10055\n",
      "85.0 92\n",
      "Number of deleted rows: 8\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 106\n",
      "Number of deleted rows: 6\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 52\n",
      "Number of deleted rows: 91\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 61\n",
      "Number of deleted rows: 96\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 70\n",
      "Number of deleted rows: 62\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 79\n",
      "Number of deleted rows: 16\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 88\n",
      "Number of deleted rows: 61\n",
      "\n",
      "Size of original panda file: 10055\n",
      "90.0 97\n",
      "Number of deleted rows: 26\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 20\n",
      "Number of deleted rows: 32\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 26\n",
      "Number of deleted rows: 66\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 33\n",
      "Number of deleted rows: 62\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 40\n",
      "Number of deleted rows: 16\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 47\n",
      "Number of deleted rows: 11\n",
      "\n",
      "Size of original panda file: 10055\n",
      "91.0 54\n",
      "Number of deleted rows: 7\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 103\n",
      "Number of deleted rows: 40\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 55\n",
      "Number of deleted rows: 225\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 65\n",
      "Number of deleted rows: 273\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 74\n",
      "Number of deleted rows: 195\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 84\n",
      "Number of deleted rows: 59\n",
      "\n",
      "Size of original panda file: 10055\n",
      "95.0 93\n",
      "Number of deleted rows: 161\n",
      "\n",
      "Size of original panda file: 10055\n",
      "97.0 27\n",
      "Number of deleted rows: 9\n",
      "\n",
      "Size of original panda file: 10055\n",
      "97.0 34\n",
      "Number of deleted rows: 10\n",
      "\n",
      "Size of original panda file: 10055\n",
      "97.0 41\n",
      "Number of deleted rows: 8\n",
      "\n",
      "Size of original panda file: 10055\n",
      "97.0 48\n",
      "Number of deleted rows: 5\n",
      "\n",
      "Size of original panda file: 10055\n",
      "97.0 55\n",
      "Number of deleted rows: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(file_list[0], key=None)\n",
    "df['A'] = pd.to_numeric(df['A'])\n",
    "df['Z'] = pd.to_numeric(df['Z'])\n",
    "\n",
    "unique_mass = df['A'].unique()\n",
    "\n",
    "hope = []\n",
    "\n",
    "for mass_u in unique_mass:\n",
    "    df_intermediate = df[df['A'] == mass_u]\n",
    "    unique_energy = df_intermediate['Z'].unique()\n",
    "\n",
    "    for energy_u in unique_energy:\n",
    "        df_copy = df.copy()  # Create a copy of the original DataFrame\n",
    "\n",
    "        print(f\"Size of original panda file: {len(df_copy)}\")\n",
    "        print(mass_u, energy_u) \n",
    "\n",
    "        # Step 1: Apply the first condition and create an intermediate DataFrame\n",
    "        df_intermediate = df_copy[df_copy['A'] == mass_u]\n",
    "\n",
    "        # Step 2: Apply the second condition to the intermediate DataFrame and create the final filtered DataFrame\n",
    "        df_filtered = df_intermediate[df_intermediate['Z'] == energy_u]\n",
    "\n",
    "        # Check for duplicates in df_copy\n",
    "        duplicated_rows = df_copy[df_copy.duplicated()]\n",
    "#         print(f\"Duplicated rows in df_copy:\\n{duplicated_rows}\")\n",
    "\n",
    "        # Get the indices of rows to be dropped from df_copy\n",
    "        rows_to_drop = df_filtered.index\n",
    "\n",
    "        # Drop the rows from df_copy\n",
    "        df_copy = df_copy.drop(rows_to_drop)\n",
    "\n",
    "        # Drop all duplicate rows\n",
    "        df_copy = df_copy.drop_duplicates()\n",
    "        \n",
    "        print(f'Number of deleted rows: {len(df_filtered)}')\n",
    "#         print(f'Size of new panda file: {len(df_copy)}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492e6746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of energies for each Mass (A):\n",
      "Mass 100.0: 9 energies, Average Count: 170.88888888888889\n",
      "Mass 104.0: 6 energies, Average Count: 102.5\n",
      "Mass 105.0: 5 energies, Average Count: 223.6\n",
      "Mass 110.0: 6 energies, Average Count: 31.333333333333332\n",
      "Mass 127.0: 2 energies, Average Count: 44.5\n",
      "Mass 130.0: 8 energies, Average Count: 139.875\n",
      "Mass 133.0: 2 energies, Average Count: 102.0\n",
      "Mass 135.0: 1 energies, Average Count: 197.0\n",
      "Mass 136.0: 5 energies, Average Count: 107.0\n",
      "Mass 140.0: 3 energies, Average Count: 321.6666666666667\n",
      "Mass 143.0: 4 energies, Average Count: 442.75\n",
      "Mass 149.0: 2 energies, Average Count: 34.0\n",
      "Mass 80.0: 1 energies, Average Count: 1.0\n",
      "Mass 85.0: 7 energies, Average Count: 12.857142857142858\n",
      "Mass 90.0: 7 energies, Average Count: 51.142857142857146\n",
      "Mass 91.0: 6 energies, Average Count: 32.333333333333336\n",
      "Mass 95.0: 6 energies, Average Count: 158.83333333333334\n",
      "Mass 97.0: 5 energies, Average Count: 10.4\n",
      "\n",
      "The Mass with the highest average count is 143.0 with an average count of 442.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(file_list[0], key=None)\n",
    "df['A'] = pd.to_numeric(df['A'])\n",
    "df['Z'] = pd.to_numeric(df['Z'])\n",
    "\n",
    "unique_mass = df['A'].unique()\n",
    "\n",
    "mass_counts = {}\n",
    "\n",
    "for mass_u in unique_mass:\n",
    "    df_intermediate = df[df['A'] == mass_u]\n",
    "    unique_energy = df_intermediate['Z'].unique()\n",
    "\n",
    "    energy_count = len(unique_energy)  # Number of energies for the current Mass (A)\n",
    "\n",
    "    for energy_u in unique_energy:\n",
    "        df_copy = df.copy()  # Create a copy of the original DataFrame\n",
    "\n",
    "        # Step 1: Apply the first condition and create an intermediate DataFrame\n",
    "        df_intermediate = df_copy[df_copy['A'] == mass_u]\n",
    "\n",
    "        # Step 2: Apply the second condition to the intermediate DataFrame and create the final filtered DataFrame\n",
    "        df_filtered = df_intermediate[df_intermediate['Z'] == energy_u]\n",
    "\n",
    "        # Get the indices of rows to be dropped from df_copy\n",
    "        rows_to_drop = df_filtered.index\n",
    "\n",
    "        # Drop the rows from df_copy\n",
    "        df_copy = df_copy.drop(rows_to_drop)\n",
    "\n",
    "        # Drop all duplicate rows\n",
    "        df_copy = df_copy.drop_duplicates()\n",
    "\n",
    "        # Calculate the count for the current Mass (A)\n",
    "        count = len(df_filtered)\n",
    "\n",
    "        # Store the count in the dictionary\n",
    "        if mass_u in mass_counts:\n",
    "            mass_counts[mass_u].append(count)\n",
    "        else:\n",
    "            mass_counts[mass_u] = [count]\n",
    "\n",
    "# Calculate the average count for each Mass (A)\n",
    "average_counts = {mass: sum(counts) / len(counts) for mass, counts in mass_counts.items()}\n",
    "\n",
    "print(\"Number of energies for each Mass (A):\")\n",
    "for mass, energy_counts in mass_counts.items():\n",
    "    print(f\"Mass {mass}: {len(energy_counts)} energies, Average Count: {average_counts[mass]}\")\n",
    "\n",
    "# Find the Mass (A) with the highest average count\n",
    "max_average_mass = max(average_counts, key=average_counts.get)\n",
    "\n",
    "print()\n",
    "print(f\"The Mass with the highest average count is {max_average_mass} with an average count of {average_counts[max_average_mass]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
